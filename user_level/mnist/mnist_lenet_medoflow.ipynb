{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with LeNet-5\n",
    "\n",
    "This file is extracted from mnist_dlsys.py, with extra code about logging and plotting added."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import argparse\n",
    "import six.moves.cPickle as pickle\n",
    "import gzip\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tvm\n",
    "from system_level import autodiff as ad\n",
    "from system_level import tvm_op\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = \"llvm\"\n",
    "tgt_host = \"llvm\"\n",
    "\n",
    "# create context object\n",
    "executor_ctx = tvm.device(tgt, 0)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "def convert_to_one_hot(vals):\n",
    "    \"\"\"Helper method to convert label array to one-hot array.\"\"\"\n",
    "    one_hot_vals = np.zeros((vals.size, 10))\n",
    "    one_hot_vals[np.arange(vals.size), vals] = 1\n",
    "    return one_hot_vals\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and examine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded train_set, valid_set and test_set.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load the dataset\n",
    "Code adapted from http://deeplearning.net/tutorial/code/logistic_sgd.py\n",
    "\n",
    ":type dataset: string\n",
    ":param dataset: the path to the dataset (here MNIST)\n",
    "\"\"\"\n",
    "# Download the MNIST dataset if it is not present\n",
    "dataset = \"mnist.pkl.gz\"\n",
    "\n",
    "data_dir, data_file = os.path.split(dataset)\n",
    "if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "    # Check if dataset is in the data directory.\n",
    "    new_path = os.path.join(\n",
    "        os.path.split(__file__)[0],\n",
    "        dataset\n",
    "    )\n",
    "    if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "        dataset = new_path\n",
    "\n",
    "if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "    from six.moves import urllib\n",
    "    origin = (\n",
    "        'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "    )\n",
    "    print('Downloading data from %s' % origin)\n",
    "    urllib.request.urlretrieve(origin, dataset)\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "# Load the dataset\n",
    "with gzip.open(dataset, 'rb') as f:\n",
    "    try:\n",
    "        train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    except:\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "# train_set, valid_set, test_set format: tuple(input, target)\n",
    "# input is a numpy.ndarray of 2 dimensions (a matrix), np.float32\n",
    "# where each row corresponds to an example. target is a\n",
    "# numpy.ndarray of 1 dimension (vector), np.int64 that has the same length\n",
    "# as the number of rows in the input. It should give the target\n",
    "# to the example with the same index in the input.\n",
    "print('Loaded train_set, valid_set and test_set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(50000, 1, 28, 28)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0].shape)\n",
    "print(train_set[1].shape)\n",
    "\n",
    "# because we use lenet, we need to reshape the data\n",
    "train_set = (train_set[0].reshape((-1, 1, 28, 28)), train_set[1])\n",
    "valid_set = (valid_set[0].reshape((-1, 1, 28, 28)), valid_set[1])\n",
    "test_set = (test_set[0].reshape((-1, 1, 28, 28)), test_set[1])\n",
    "\n",
    "print(train_set[0].shape)\n",
    "print(train_set[1].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the computational graph\n",
    "\n",
    "![](../images/lenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Declaring Weights ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Declaring Weights ===\")\n",
    "\n",
    "F1 = ad.Variable(name=\"F1\") # conv2d kernel\n",
    "BN1_gamma = ad.Variable(name=\"BN1_gamma\") # batch norm\n",
    "BN1_beta = ad.Variable(name=\"BN1_beta\") # batch norm\n",
    "\n",
    "F2 = ad.Variable(name=\"F2\") # conv2d kernel\n",
    "BN2_gamma = ad.Variable(name=\"BN2_gamma\") # batch norm\n",
    "BN2_beta = ad.Variable(name=\"BN2_beta\") # batch norm\n",
    "\n",
    "W1 = ad.Variable(name=\"W1\") # fully connected weight\n",
    "b1 = ad.Variable(name=\"b1\") # fully connected bias\n",
    "\n",
    "W2 = ad.Variable(name=\"W2\") # fully connected weight\n",
    "b2 = ad.Variable(name=\"b2\") # fully connected bias\n",
    "\n",
    "W3 = ad.Variable(name=\"W3\") # fully connected weight\n",
    "b3 = ad.Variable(name=\"b3\") # fully connected bias\n",
    "\n",
    "X = ad.Variable(name=\"X\") # input\n",
    "y_ = ad.Variable(name=\"y_\") # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Constructing Computational Graph ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Constructing Computational Graph ===\")\n",
    "\n",
    "# CNN1: bn(maxpool(relu(conv(X F))))\n",
    "z1 = ad.conv2d_op(X, F1)\n",
    "z2 = ad.relu_op(z1)\n",
    "z3 = ad.maxpool2d_op(z2, pool_size=2, stride=2)\n",
    "z4 = ad.batchnorm2d_op(z3, BN1_gamma, BN1_beta)\n",
    "\n",
    "# CNN2: bn(maxpool(relu(conv(z3, F2))))\n",
    "z5 = ad.conv2d_op(z4, F2)\n",
    "z6 = ad.relu_op(z5)\n",
    "z7 = ad.maxpool2d_op(z6, pool_size=2, stride=2)\n",
    "z8 = ad.batchnorm2d_op(z7, BN2_gamma, BN2_beta)\n",
    "\n",
    "# flatten\n",
    "CHW = (16, 4, 4)\n",
    "z9 = ad.flatten_op(z8, CHW)\n",
    "\n",
    "# mlp: relu(matmul(z7, W1) + b1)\n",
    "z10 = ad.matmul_op(z9, W1)\n",
    "z11 = ad.relu_op(z10 + ad.broadcastto_op(b1, z10))\n",
    "z12 = ad.matmul_op(z11, W2) \n",
    "z13 = ad.relu_op(z12 + ad.broadcastto_op(b2, z12))\n",
    "z14 = ad.matmul_op(z13, W3)\n",
    "y = z14 + ad.broadcastto_op(b3, z14)\n",
    "\n",
    "# softmax & cross entropy\n",
    "loss = ad.softmaxcrossentropy_op(y, y_)\n",
    "\n",
    "grad_F1, grad_BN1_gamma, grad_BN1_beta, grad_F2, grad_BN2_gamma, grad_BN2_beta, grad_W1, grad_W2, grad_W3, grad_b1, grad_b2, grad_b3 = ad.gradients(\n",
    "    loss, [F1, BN1_gamma, BN1_beta, F2, BN2_gamma, BN2_beta, W1, W2, W3, b1, b2, b3])\n",
    "     \n",
    "executor = ad.Executor(\n",
    "    [loss, grad_F1, grad_BN1_gamma, grad_BN1_beta, grad_F2, grad_BN2_gamma, grad_BN2_beta, grad_W1, grad_W2, grad_W3, grad_b1, grad_b2, grad_b3, y],\n",
    "    ctx=executor_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initializing Weights ===\n",
      "Start training loop...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Initializing Weights ===\")\n",
    "\n",
    "# Read input data\n",
    "train_set_x, train_set_y = train_set\n",
    "valid_set_x, valid_set_y = valid_set\n",
    "test_set_x, test_set_y = test_set\n",
    "# Set up minibatch\n",
    "batch_size = 64\n",
    "n_train_batches = train_set_x.shape[0] // batch_size\n",
    "n_valid_batches = valid_set_x.shape[0] // batch_size\n",
    "\n",
    "print(\"Start training loop...\")\n",
    "\n",
    "# Initialize parameters\n",
    "rand = np.random.RandomState(seed=42)\n",
    "# n*1*28*28\n",
    "F1_val = rand.normal(scale=0.1, size=(6, 1, 5, 5)).astype(np.float32)\n",
    "# n*6*24*24\n",
    "# maxpool\n",
    "# n*6*12*12\n",
    "BN1_gamma_val = np.ones(shape=(1, 6, 1, 1)).astype(np.float32)\n",
    "BN1_beta_val = np.zeros(shape=(1, 6, 1, 1)).astype(np.float32)\n",
    "\n",
    "F2_val = rand.normal(scale=0.1, size=(16, 6, 5, 5)).astype(np.float32)\n",
    "# n*16*8*8\n",
    "# maxpool\n",
    "# n*16*4*4\n",
    "BN2_gamma_val = np.ones(shape=(1, 16, 1, 1)).astype(np.float32)\n",
    "BN2_beta_val = np.zeros(shape=(1, 16, 1, 1)).astype(np.float32)\n",
    "\n",
    "W1_val = rand.normal(scale=0.1, size=(16*4*4, 120)).astype(np.float32)\n",
    "b1_val = rand.normal(scale=0.1, size=(120)).astype(np.float32)\n",
    "\n",
    "W2_val = rand.normal(scale=0.1, size=(120, 84)).astype(np.float32)\n",
    "b2_val = rand.normal(scale=0.1, size=(84)).astype(np.float32)\n",
    "\n",
    "W3_val = rand.normal(scale=0.1, size=(84, 10)).astype(np.float32)\n",
    "b3_val = rand.normal(scale=0.1, size=(10)).astype(np.float32)\n",
    "\n",
    "X_val = np.empty(shape=(batch_size, 1, 28, 28), dtype=np.float32)\n",
    "y_val = np.empty(shape=(batch_size, 10), dtype=np.float32)\n",
    "\n",
    "valid_X_val = np.empty(shape=(batch_size, 1, 28, 28), dtype=np.float32)\n",
    "valid_y_val = np.empty(shape=(batch_size, 10), dtype=np.float32)\n",
    "\n",
    "test_X_val = np.empty(shape=(1, 1, 28, 28), dtype=np.float32)\n",
    "test_y_val = np.empty(shape=(1, 10), dtype=np.float32)\n",
    "\n",
    "# wrap with tvm.nd.array\n",
    "F1_val = tvm.nd.array(F1_val)\n",
    "BN1_gamma_val = tvm.nd.array(BN1_gamma_val)\n",
    "BN1_beta_val = tvm.nd.array(BN1_beta_val)\n",
    "F2_val = tvm.nd.array(F2_val)\n",
    "BN2_gamma_val = tvm.nd.array(BN2_gamma_val)\n",
    "BN2_beta_val = tvm.nd.array(BN2_beta_val)\n",
    "W1_val = tvm.nd.array(W1_val)\n",
    "b1_val = tvm.nd.array(b1_val)\n",
    "W2_val = tvm.nd.array(W2_val)\n",
    "b2_val = tvm.nd.array(b2_val)\n",
    "W3_val = tvm.nd.array(W3_val)\n",
    "b3_val = tvm.nd.array(b3_val)\n",
    "\n",
    "X_val = tvm.nd.array(X_val)\n",
    "y_val = tvm.nd.array(y_val)\n",
    "valid_X_val = tvm.nd.array(valid_X_val)\n",
    "valid_y_val = tvm.nd.array(valid_y_val)\n",
    "test_X_val = tvm.nd.array(test_X_val)\n",
    "test_y_val = tvm.nd.array(test_y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "lr = 0.0005\n",
    "# JIT compile sgd update ops\n",
    "F1_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    F1_val.shape, lr, tgt, tgt_host, \"F1_sgd_update\")\n",
    "BN1_gamma_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    BN1_gamma_val.shape, lr, tgt, tgt_host, \"BN1_gamma_sgd_update\")\n",
    "BN1_beta_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    BN1_beta_val.shape, lr, tgt, tgt_host, \"BN1_beta_sgd_update\")\n",
    "\n",
    "F2_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    F2_val.shape, lr, tgt, tgt_host, \"F2_sgd_update\")\n",
    "BN2_gamma_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    BN2_gamma_val.shape, lr, tgt, tgt_host, \"BN2_gamma_sgd_update\")\n",
    "BN2_beta_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    BN2_beta_val.shape, lr, tgt, tgt_host, \"BN2_beta_sgd_update\")\n",
    "\n",
    "W1_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    W1_val.shape, lr, tgt, tgt_host, \"W1_sgd_update\")\n",
    "W2_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    W2_val.shape, lr, tgt, tgt_host, \"W2_sgd_update\")\n",
    "W3_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    W3_val.shape, lr, tgt, tgt_host, \"W3_sgd_update\")\n",
    "b1_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    b1_val.shape, lr, tgt, tgt_host, \"b1_sgd_update\")\n",
    "b2_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    b2_val.shape, lr, tgt, tgt_host, \"b2_sgd_update\")\n",
    "b3_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    b3_val.shape, lr, tgt, tgt_host, \"b3_sgd_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** EPOCH 1 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/781 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [16384], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [30720], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [7680], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 256], []), B_1: B_3: Buffer(B_2, float32, [256, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 120], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 30) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*480) + (j.outer*4)) + j.inner.init), 120, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 64) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*480) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 120, 4)] = (compute[ramp(cse_var_1, 120, 4)] + (A[ramp(((i.outer*1024) + (k.outer*4)), 256, 4)]*broadcast(B[(((k.outer*480) + cse_var_2) + j.inner)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*480) + cse_var_4) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 120, 4)] = (compute[ramp(cse_var_3, 120, 4)] + (A[ramp((((i.outer*1024) + (k.outer*4)) + 1), 256, 4)]*broadcast(B[((((k.outer*480) + cse_var_4) + j.inner_1) + 120)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*480) + cse_var_6) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 120, 4)] = (compute[ramp(cse_var_5, 120, 4)] + (A[ramp((((i.outer*1024) + (k.outer*4)) + 2), 256, 4)]*broadcast(B[((((k.outer*480) + cse_var_6) + j.inner_2) + 240)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*480) + cse_var_8) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 120, 4)] = (compute[ramp(cse_var_7, 120, 4)] + (A[ramp((((i.outer*1024) + (k.outer*4)) + 3), 256, 4)]*broadcast(B[((((k.outer*480) + cse_var_8) + j.inner_3) + 360)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [7680], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [10080], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [5376], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 120], []), B_1: B_3: Buffer(B_2, float32, [120, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 84], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 21) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*336) + (j.outer*4)) + j.inner.init), 84, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 30) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*336) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 84, 4)] = (compute[ramp(cse_var_1, 84, 4)] + (A[ramp(((i.outer*480) + (k.outer*4)), 120, 4)]*broadcast(B[(((k.outer*336) + cse_var_2) + j.inner)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*336) + cse_var_4) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 84, 4)] = (compute[ramp(cse_var_3, 84, 4)] + (A[ramp((((i.outer*480) + (k.outer*4)) + 1), 120, 4)]*broadcast(B[((((k.outer*336) + cse_var_4) + j.inner_1) + 84)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*336) + cse_var_6) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 84, 4)] = (compute[ramp(cse_var_5, 84, 4)] + (A[ramp((((i.outer*480) + (k.outer*4)) + 2), 120, 4)]*broadcast(B[((((k.outer*336) + cse_var_6) + j.inner_2) + 168)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*336) + cse_var_8) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 84, 4)] = (compute[ramp(cse_var_7, 84, 4)] + (A[ramp((((i.outer*480) + (k.outer*4)) + 3), 120, 4)]*broadcast(B[((((k.outer*336) + cse_var_8) + j.inner_3) + 252)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [5376], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [840], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [640], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 84], []), B_1: B_3: Buffer(B_2, float32, [84, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 10], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 3) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner.init, 2)) < 5), dtype=bool) {\n",
      "          compute[ramp((((i.outer*40) + (j.outer*4)) + j.inner.init), 10, 4)] = broadcast(0f32, 4)\n",
      "        }\n",
      "      }\n",
      "      for (k.outer: int32, 0, 21) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_2: int32 = (j.outer*4)\n",
      "            let cse_var_1: int32 = (((i.outer*40) + cse_var_2) + j.inner)\n",
      "            compute[ramp(cse_var_1, 10, 4)] = (compute[ramp(cse_var_1, 10, 4)] + (A[ramp(((i.outer*336) + (k.outer*4)), 84, 4)]*broadcast(B[(((k.outer*40) + cse_var_2) + j.inner)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_1, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_4: int32 = (j.outer*4)\n",
      "            let cse_var_3: int32 = (((i.outer*40) + cse_var_4) + j.inner_1)\n",
      "            compute[ramp(cse_var_3, 10, 4)] = (compute[ramp(cse_var_3, 10, 4)] + (A[ramp((((i.outer*336) + (k.outer*4)) + 1), 84, 4)]*broadcast(B[((((k.outer*40) + cse_var_4) + j.inner_1) + 10)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_2, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_6: int32 = (j.outer*4)\n",
      "            let cse_var_5: int32 = (((i.outer*40) + cse_var_6) + j.inner_2)\n",
      "            compute[ramp(cse_var_5, 10, 4)] = (compute[ramp(cse_var_5, 10, 4)] + (A[ramp((((i.outer*336) + (k.outer*4)) + 2), 84, 4)]*broadcast(B[((((k.outer*40) + cse_var_6) + j.inner_2) + 20)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_3, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_8: int32 = (j.outer*4)\n",
      "            let cse_var_7: int32 = (((i.outer*40) + cse_var_8) + j.inner_3)\n",
      "            compute[ramp(cse_var_7, 10, 4)] = (compute[ramp(cse_var_7, 10, 4)] + (A[ramp((((i.outer*336) + (k.outer*4)) + 3), 84, 4)]*broadcast(B[((((k.outer*40) + cse_var_8) + j.inner_3) + 30)], 4)))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [640], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [840], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [5376], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 10], []), B_1: B_3: Buffer(B_2, float32, [84, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 84], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 21) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*336) + (j.outer*4)) + j.inner.init), 84, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 3) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (k.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*336) + (j.outer*4)) + j.inner)\n",
      "          compute[ramp(cse_var_1, 84, 4)] = (compute[ramp(cse_var_1, 84, 4)] + (A[ramp(((i.outer*40) + cse_var_2), 10, 4)]*broadcast(B[(((j.outer*40) + (j.inner*10)) + cse_var_2)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (k.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*336) + (j.outer*4)) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 84, 4)] = (compute[ramp(cse_var_3, 84, 4)] + (A[ramp((((i.outer*40) + cse_var_4) + 1), 10, 4)]*broadcast(B[((((j.outer*40) + (j.inner_1*10)) + cse_var_4) + 1)], 4)))\n",
      "        }\n",
      "        if @tir.likely((k.outer < 2), dtype=bool) {\n",
      "          for (j.inner_2: int32, 0, 4) {\n",
      "            let cse_var_6: int32 = (k.outer*4)\n",
      "            let cse_var_5: int32 = (((i.outer*336) + (j.outer*4)) + j.inner_2)\n",
      "            compute[ramp(cse_var_5, 84, 4)] = (compute[ramp(cse_var_5, 84, 4)] + (A[ramp((((i.outer*40) + cse_var_6) + 2), 10, 4)]*broadcast(B[((((j.outer*40) + (j.inner_2*10)) + cse_var_6) + 2)], 4)))\n",
      "          }\n",
      "        }\n",
      "        if @tir.likely((k.outer < 2), dtype=bool) {\n",
      "          for (j.inner_3: int32, 0, 4) {\n",
      "            let cse_var_8: int32 = (k.outer*4)\n",
      "            let cse_var_7: int32 = (((i.outer*336) + (j.outer*4)) + j.inner_3)\n",
      "            compute[ramp(cse_var_7, 84, 4)] = (compute[ramp(cse_var_7, 84, 4)] + (A[ramp((((i.outer*40) + cse_var_8) + 3), 10, 4)]*broadcast(B[((((j.outer*40) + (j.inner_3*10)) + cse_var_8) + 3)], 4)))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [5376], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [10080], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [7680], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 84], []), B_1: B_3: Buffer(B_2, float32, [120, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 120], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 30) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*480) + (j.outer*4)) + j.inner.init), 120, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 21) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (k.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*480) + (j.outer*4)) + j.inner)\n",
      "          compute[ramp(cse_var_1, 120, 4)] = (compute[ramp(cse_var_1, 120, 4)] + (A[ramp(((i.outer*336) + cse_var_2), 84, 4)]*broadcast(B[(((j.outer*336) + (j.inner*84)) + cse_var_2)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (k.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*480) + (j.outer*4)) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 120, 4)] = (compute[ramp(cse_var_3, 120, 4)] + (A[ramp((((i.outer*336) + cse_var_4) + 1), 84, 4)]*broadcast(B[((((j.outer*336) + (j.inner_1*84)) + cse_var_4) + 1)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (k.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*480) + (j.outer*4)) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 120, 4)] = (compute[ramp(cse_var_5, 120, 4)] + (A[ramp((((i.outer*336) + cse_var_6) + 2), 84, 4)]*broadcast(B[((((j.outer*336) + (j.inner_2*84)) + cse_var_6) + 2)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (k.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*480) + (j.outer*4)) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 120, 4)] = (compute[ramp(cse_var_7, 120, 4)] + (A[ramp((((i.outer*336) + cse_var_8) + 3), 84, 4)]*broadcast(B[((((j.outer*336) + (j.inner_3*84)) + cse_var_8) + 3)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [7680], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [30720], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [16384], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 120], []), B_1: B_3: Buffer(B_2, float32, [256, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 256], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 64) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*1024) + (j.outer*4)) + j.inner.init), 256, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 30) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (k.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*1024) + (j.outer*4)) + j.inner)\n",
      "          compute[ramp(cse_var_1, 256, 4)] = (compute[ramp(cse_var_1, 256, 4)] + (A[ramp(((i.outer*480) + cse_var_2), 120, 4)]*broadcast(B[(((j.outer*480) + (j.inner*120)) + cse_var_2)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (k.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*1024) + (j.outer*4)) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 256, 4)] = (compute[ramp(cse_var_3, 256, 4)] + (A[ramp((((i.outer*480) + cse_var_4) + 1), 120, 4)]*broadcast(B[((((j.outer*480) + (j.inner_1*120)) + cse_var_4) + 1)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (k.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*1024) + (j.outer*4)) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 256, 4)] = (compute[ramp(cse_var_5, 256, 4)] + (A[ramp((((i.outer*480) + cse_var_6) + 2), 120, 4)]*broadcast(B[((((j.outer*480) + (j.inner_2*120)) + cse_var_6) + 2)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (k.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*1024) + (j.outer*4)) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 256, 4)] = (compute[ramp(cse_var_7, 256, 4)] + (A[ramp((((i.outer*480) + cse_var_8) + 3), 120, 4)]*broadcast(B[((((j.outer*480) + (j.inner_3*120)) + cse_var_8) + 3)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [16384], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [7680], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [30720], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 256], []), B_1: B_3: Buffer(B_2, float32, [64, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [256, 120], [])} {\n",
      "  for (i.outer: int32, 0, 64) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 30) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*480) + (j.outer*4)) + j.inner.init), 120, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 16) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*480) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 120, 4)] = (compute[ramp(cse_var_1, 120, 4)] + (A[ramp(((k.outer*1024) + (i.outer*4)), 1, 4)]*broadcast(B[(((k.outer*480) + cse_var_2) + j.inner)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*480) + cse_var_4) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 120, 4)] = (compute[ramp(cse_var_3, 120, 4)] + (A[ramp((((k.outer*1024) + (i.outer*4)) + 256), 1, 4)]*broadcast(B[((((k.outer*480) + cse_var_4) + j.inner_1) + 120)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*480) + cse_var_6) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 120, 4)] = (compute[ramp(cse_var_5, 120, 4)] + (A[ramp((((k.outer*1024) + (i.outer*4)) + 512), 1, 4)]*broadcast(B[((((k.outer*480) + cse_var_6) + j.inner_2) + 240)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*480) + cse_var_8) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 120, 4)] = (compute[ramp(cse_var_7, 120, 4)] + (A[ramp((((k.outer*1024) + (i.outer*4)) + 768), 1, 4)]*broadcast(B[((((k.outer*480) + cse_var_8) + j.inner_3) + 360)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [7680], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [5376], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [10080], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 120], []), B_1: B_3: Buffer(B_2, float32, [64, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [120, 84], [])} {\n",
      "  for (i.outer: int32, 0, 30) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 21) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*336) + (j.outer*4)) + j.inner.init), 84, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 16) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*336) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 84, 4)] = (compute[ramp(cse_var_1, 84, 4)] + (A[ramp(((k.outer*480) + (i.outer*4)), 1, 4)]*broadcast(B[(((k.outer*336) + cse_var_2) + j.inner)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*336) + cse_var_4) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 84, 4)] = (compute[ramp(cse_var_3, 84, 4)] + (A[ramp((((k.outer*480) + (i.outer*4)) + 120), 1, 4)]*broadcast(B[((((k.outer*336) + cse_var_4) + j.inner_1) + 84)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*336) + cse_var_6) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 84, 4)] = (compute[ramp(cse_var_5, 84, 4)] + (A[ramp((((k.outer*480) + (i.outer*4)) + 240), 1, 4)]*broadcast(B[((((k.outer*336) + cse_var_6) + j.inner_2) + 168)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*336) + cse_var_8) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 84, 4)] = (compute[ramp(cse_var_7, 84, 4)] + (A[ramp((((k.outer*480) + (i.outer*4)) + 360), 1, 4)]*broadcast(B[((((k.outer*336) + cse_var_8) + j.inner_3) + 252)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [5376], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [640], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [840], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 84], []), B_1: B_3: Buffer(B_2, float32, [64, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [84, 10], [])} {\n",
      "  for (i.outer: int32, 0, 21) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 3) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner.init, 2)) < 5), dtype=bool) {\n",
      "          compute[ramp((((i.outer*40) + (j.outer*4)) + j.inner.init), 10, 4)] = broadcast(0f32, 4)\n",
      "        }\n",
      "      }\n",
      "      for (k.outer: int32, 0, 16) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_2: int32 = (j.outer*4)\n",
      "            let cse_var_1: int32 = (((i.outer*40) + cse_var_2) + j.inner)\n",
      "            compute[ramp(cse_var_1, 10, 4)] = (compute[ramp(cse_var_1, 10, 4)] + (A[ramp(((k.outer*336) + (i.outer*4)), 1, 4)]*broadcast(B[(((k.outer*40) + cse_var_2) + j.inner)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_1, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_4: int32 = (j.outer*4)\n",
      "            let cse_var_3: int32 = (((i.outer*40) + cse_var_4) + j.inner_1)\n",
      "            compute[ramp(cse_var_3, 10, 4)] = (compute[ramp(cse_var_3, 10, 4)] + (A[ramp((((k.outer*336) + (i.outer*4)) + 84), 1, 4)]*broadcast(B[((((k.outer*40) + cse_var_4) + j.inner_1) + 10)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_2, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_6: int32 = (j.outer*4)\n",
      "            let cse_var_5: int32 = (((i.outer*40) + cse_var_6) + j.inner_2)\n",
      "            compute[ramp(cse_var_5, 10, 4)] = (compute[ramp(cse_var_5, 10, 4)] + (A[ramp((((k.outer*336) + (i.outer*4)) + 168), 1, 4)]*broadcast(B[((((k.outer*40) + cse_var_6) + j.inner_2) + 20)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_3, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_8: int32 = (j.outer*4)\n",
      "            let cse_var_7: int32 = (((i.outer*40) + cse_var_8) + j.inner_3)\n",
      "            compute[ramp(cse_var_7, 10, 4)] = (compute[ramp(cse_var_7, 10, 4)] + (A[ramp((((k.outer*336) + (i.outer*4)) + 252), 1, 4)]*broadcast(B[((((k.outer*40) + cse_var_8) + j.inner_3) + 30)], 4)))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [10:59<00:00,  1.18it/s]\n",
      "100%|██████████| 781/781 [10:49<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9325184058898848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9322916666666666\n",
      "epoch 1 loss = 0.2155\n",
      "***** EPOCH 2 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:04<00:00,  1.18it/s]\n",
      "100%|██████████| 781/781 [11:03<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9509042893725992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:14<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9475160256410257\n",
      "epoch 2 loss = 0.1546\n",
      "***** EPOCH 3 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:12<00:00,  1.16it/s]\n",
      "100%|██████████| 781/781 [11:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9602672855313701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:11<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9540264423076923\n",
      "epoch 3 loss = 0.1265\n",
      "***** EPOCH 4 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:09<00:00,  1.17it/s]\n",
      "100%|██████████| 781/781 [11:07<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.96636923815621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:15<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9563301282051282\n",
      "epoch 4 loss = 0.1085\n",
      "***** EPOCH 5 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:13<00:00,  1.16it/s]\n",
      "100%|██████████| 781/781 [11:27<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9706306017925737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:22<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9588341346153846\n",
      "epoch 5 loss = 0.0953\n",
      "***** EPOCH 6 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:53<00:00,  1.09it/s]\n",
      "100%|██████████| 781/781 [11:43<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9739116517285531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:22<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9611378205128205\n",
      "epoch 6 loss = 0.0848\n",
      "***** EPOCH 7 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:48<00:00,  1.10it/s]\n",
      "100%|██████████| 781/781 [11:47<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9769326184379001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:23<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9622395833333334\n",
      "epoch 7 loss = 0.0760\n",
      "***** EPOCH 8 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:42<00:00,  1.11it/s]\n",
      "100%|██████████| 781/781 [11:40<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9790132842509603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:20<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9639423076923077\n",
      "epoch 8 loss = 0.0688\n",
      "***** EPOCH 9 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:41<00:00,  1.11it/s]\n",
      "100%|██████████| 781/781 [10:54<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9810539372599232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:20<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9652443910256411\n",
      "epoch 9 loss = 0.0624\n",
      "***** EPOCH 10 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [11:40<00:00,  1.11it/s]\n",
      "100%|██████████| 781/781 [11:42<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.9833546734955185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:20<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on valid set:  0.9660456730769231\n",
      "epoch 10 loss = 0.0566\n",
      "Average Time per Training Epoch = 1504.700289 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_measurements = []\n",
    "train_acc_values = []\n",
    "val_acc_values = []\n",
    "loss_values = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    print(f\"***** EPOCH {i+1} *****\")\n",
    "    \n",
    "    # train on train set\n",
    "    start_time = time.time()\n",
    "    for minibatch_index in tqdm(range(n_train_batches)):\n",
    "        minibatch_start = minibatch_index * batch_size\n",
    "        minibatch_end = (minibatch_index + 1) * batch_size\n",
    "        X_val.copyfrom(train_set_x[minibatch_start:minibatch_end])\n",
    "        y_val.copyfrom(\n",
    "            convert_to_one_hot(train_set_y[minibatch_start:minibatch_end]))\n",
    "        \n",
    "        _, grad_F1_val, grad_BN1_gamma_val, grad_BN1_beta_val, \\\n",
    "            grad_F2_val, grad_BN2_gamma_val, grad_BN2_beta_val, \\\n",
    "            grad_W1_val, grad_W2_val, grad_W3_val, \\\n",
    "            grad_b1_val, grad_b2_val, grad_b3_val, _ = executor.run(\n",
    "                feed_dict={\n",
    "                    X: X_val,\n",
    "                    y_: y_val,\n",
    "                    F1: F1_val,\n",
    "                    BN1_gamma: BN1_gamma_val,\n",
    "                    BN1_beta: BN1_beta_val,\n",
    "                    F2: F2_val,\n",
    "                    BN2_gamma: BN2_gamma_val,\n",
    "                    BN2_beta: BN2_beta_val,\n",
    "                    W1: W1_val,\n",
    "                    W2: W2_val,\n",
    "                    W3: W3_val,\n",
    "                    b1: b1_val,\n",
    "                    b2: b2_val,\n",
    "                    b3: b3_val})\n",
    "        # SGD update\n",
    "        F1_sgd_update_func(F1_val, grad_F1_val, F1_val)\n",
    "        BN1_gamma_sgd_update_func(BN1_gamma_val, grad_BN1_gamma_val, BN1_gamma_val)\n",
    "        BN1_beta_sgd_update_func(BN1_beta_val, grad_BN1_beta_val, BN1_beta_val)\n",
    "        F2_sgd_update_func(F2_val, grad_F2_val, F2_val)\n",
    "        BN2_gamma_sgd_update_func(BN2_gamma_val, grad_BN2_gamma_val, BN2_gamma_val)\n",
    "        BN2_beta_sgd_update_func(BN2_beta_val, grad_BN2_beta_val, BN2_beta_val)\n",
    "        W1_sgd_update_func(W1_val, grad_W1_val, W1_val)\n",
    "        W2_sgd_update_func(W2_val, grad_W2_val, W2_val)\n",
    "        W3_sgd_update_func(W3_val, grad_W3_val, W3_val)\n",
    "        b1_sgd_update_func(b1_val, grad_b1_val, b1_val)\n",
    "        b2_sgd_update_func(b2_val, grad_b2_val, b2_val)\n",
    "        b3_sgd_update_func(b3_val, grad_b3_val, b3_val)\n",
    "    \n",
    "    # eval on train set\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    loss_sum = 0\n",
    "    batch_num = 0\n",
    "    for minibatch_index in tqdm(range(n_train_batches)):\n",
    "        minibatch_start = minibatch_index * batch_size\n",
    "        minibatch_end = (minibatch_index + 1) * batch_size\n",
    "        X_val.copyfrom(train_set_x[minibatch_start:minibatch_end])\n",
    "        y_val.copyfrom(\n",
    "            convert_to_one_hot(train_set_y[minibatch_start:minibatch_end]))\n",
    "        loss_val, _, _, _, _, _, _, _, _, _, _, _, _, y_pred = executor.run(\n",
    "            feed_dict={\n",
    "                X: X_val,\n",
    "                y_: y_val,\n",
    "                F1: F1_val,\n",
    "                BN1_gamma: BN1_gamma_val,\n",
    "                BN1_beta: BN1_beta_val,\n",
    "                F2: F2_val,\n",
    "                BN2_gamma: BN2_gamma_val,\n",
    "                BN2_beta: BN2_beta_val,\n",
    "                W1: W1_val,\n",
    "                W2: W2_val,\n",
    "                W3: W3_val,\n",
    "                b1: b1_val,\n",
    "                b2: b2_val,\n",
    "                b3: b3_val})\n",
    "        train_correct += np.sum(y_pred.asnumpy().argmax(axis=1) == train_set_y[minibatch_start:minibatch_end])\n",
    "        train_total += minibatch_end - minibatch_start\n",
    "        loss_sum += loss_val.asnumpy()[0].astype(np.float64)\n",
    "        batch_num += 1\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_values.append(train_acc)\n",
    "    print(\"accuracy on training set: \", train_acc)\n",
    "    \n",
    "    # eval on valid set\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    for minibatch_index in tqdm(range(n_valid_batches)):\n",
    "        minibatch_start = minibatch_index * batch_size\n",
    "        minibatch_end = (minibatch_index + 1) * batch_size\n",
    "        X_val.copyfrom(valid_set_x[minibatch_start:minibatch_end])\n",
    "        y_val.copyfrom(\n",
    "            convert_to_one_hot(valid_set_y[minibatch_start:minibatch_end]))\n",
    "        _, _, _, _, _, _, _, _, _, _, _, _, _, y_pred = executor.run(\n",
    "            feed_dict={\n",
    "                X: X_val, \n",
    "                y_: y_val, \n",
    "                F1: F1_val, \n",
    "                BN1_gamma: BN1_gamma_val, \n",
    "                BN1_beta: BN1_beta_val, \n",
    "                F2: F2_val, \n",
    "                BN2_gamma: BN2_gamma_val, \n",
    "                BN2_beta: BN2_beta_val, \n",
    "                W1: W1_val, \n",
    "                W2: W2_val, \n",
    "                W3: W3_val, \n",
    "                b1: b1_val, \n",
    "                b2: b2_val, \n",
    "                b3: b3_val})\n",
    "        val_correct += np.sum(y_pred.asnumpy().argmax(axis=1) == valid_set_y[minibatch_start:minibatch_end])\n",
    "        val_total += minibatch_end - minibatch_start\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_values.append(val_acc)\n",
    "    print(\"accuracy on valid set: \", val_acc)\n",
    "    \n",
    "    average_loss = loss_sum / batch_num\n",
    "    print(f\"epoch {i+1} loss = {average_loss:.4f}\")\n",
    "    loss_values.append(average_loss)\n",
    "    time_measurements.append(time.time() - start_time)\n",
    "    \n",
    "    # save train_acc_values = [] val_acc_values = [] loss_values = [] to a json file\n",
    "    with open(\"results/medoflow_lenet.json\" , \"w\") as f:\n",
    "        json.dump({\"train_acc\": train_acc_values, \n",
    "                    \"val_acc\": val_acc_values,\n",
    "                    \"loss\": loss_values,\n",
    "                    \"time\": time_measurements}, f)\n",
    "    \n",
    "print(\"Average Time per Training Epoch = %f s\" % np.mean(time_measurements))\n",
    "# w/o batchnorm: [0.0832, 0.261, 0.1037, 0.3641, 0.2317, 0.1784]\n",
    "# w/ batchnorm: [0.0861, 0.94, 0.954, 0.9588, 0.9637, 0.9655, 0.9666, 0.9672, 0.968, 0.9694]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_acc_values, label='Training accuracy')\n",
    "plt.plot(val_acc_values, label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [256], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [30720], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [120], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 256], []), B_1: B_3: Buffer(B_2, float32, [256, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [1, 120], [])} {\n",
      "  for (j.outer: int32, 0, 30) {\n",
      "    for (j.inner.init: int32, 0, 4) {\n",
      "      compute[((j.outer*4) + j.inner.init)] = 0f32\n",
      "    }\n",
      "    for (k.outer: int32, 0, 64) {\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        let cse_var_2: int32 = (j.outer*4)\n",
      "        let cse_var_1: int32 = (cse_var_2 + j.inner)\n",
      "        compute[cse_var_1] = (compute[cse_var_1] + (A[(k.outer*4)]*B[(((k.outer*480) + cse_var_2) + j.inner)]))\n",
      "      }\n",
      "      for (j.inner_1: int32, 0, 4) {\n",
      "        let cse_var_4: int32 = (j.outer*4)\n",
      "        let cse_var_3: int32 = (cse_var_4 + j.inner_1)\n",
      "        compute[cse_var_3] = (compute[cse_var_3] + (A[((k.outer*4) + 1)]*B[((((k.outer*480) + cse_var_4) + j.inner_1) + 120)]))\n",
      "      }\n",
      "      for (j.inner_2: int32, 0, 4) {\n",
      "        let cse_var_6: int32 = (j.outer*4)\n",
      "        let cse_var_5: int32 = (cse_var_6 + j.inner_2)\n",
      "        compute[cse_var_5] = (compute[cse_var_5] + (A[((k.outer*4) + 2)]*B[((((k.outer*480) + cse_var_6) + j.inner_2) + 240)]))\n",
      "      }\n",
      "      for (j.inner_3: int32, 0, 4) {\n",
      "        let cse_var_8: int32 = (j.outer*4)\n",
      "        let cse_var_7: int32 = (cse_var_8 + j.inner_3)\n",
      "        compute[cse_var_7] = (compute[cse_var_7] + (A[((k.outer*4) + 3)]*B[((((k.outer*480) + cse_var_8) + j.inner_3) + 360)]))\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [120], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [10080], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [84], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 120], []), B_1: B_3: Buffer(B_2, float32, [120, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [1, 84], [])} {\n",
      "  for (j.outer: int32, 0, 21) {\n",
      "    for (j.inner.init: int32, 0, 4) {\n",
      "      compute[((j.outer*4) + j.inner.init)] = 0f32\n",
      "    }\n",
      "    for (k.outer: int32, 0, 30) {\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        let cse_var_2: int32 = (j.outer*4)\n",
      "        let cse_var_1: int32 = (cse_var_2 + j.inner)\n",
      "        compute[cse_var_1] = (compute[cse_var_1] + (A[(k.outer*4)]*B[(((k.outer*336) + cse_var_2) + j.inner)]))\n",
      "      }\n",
      "      for (j.inner_1: int32, 0, 4) {\n",
      "        let cse_var_4: int32 = (j.outer*4)\n",
      "        let cse_var_3: int32 = (cse_var_4 + j.inner_1)\n",
      "        compute[cse_var_3] = (compute[cse_var_3] + (A[((k.outer*4) + 1)]*B[((((k.outer*336) + cse_var_4) + j.inner_1) + 84)]))\n",
      "      }\n",
      "      for (j.inner_2: int32, 0, 4) {\n",
      "        let cse_var_6: int32 = (j.outer*4)\n",
      "        let cse_var_5: int32 = (cse_var_6 + j.inner_2)\n",
      "        compute[cse_var_5] = (compute[cse_var_5] + (A[((k.outer*4) + 2)]*B[((((k.outer*336) + cse_var_6) + j.inner_2) + 168)]))\n",
      "      }\n",
      "      for (j.inner_3: int32, 0, 4) {\n",
      "        let cse_var_8: int32 = (j.outer*4)\n",
      "        let cse_var_7: int32 = (cse_var_8 + j.inner_3)\n",
      "        compute[cse_var_7] = (compute[cse_var_7] + (A[((k.outer*4) + 3)]*B[((((k.outer*336) + cse_var_8) + j.inner_3) + 252)]))\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [84], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [840], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [10], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 84], []), B_1: B_3: Buffer(B_2, float32, [84, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [1, 10], [])} {\n",
      "  for (j.outer: int32, 0, 3) {\n",
      "    for (j.inner.init: int32, 0, 4) {\n",
      "      if @tir.likely((((j.outer*2) + floordiv(j.inner.init, 2)) < 5), dtype=bool) {\n",
      "        compute[((j.outer*4) + j.inner.init)] = 0f32\n",
      "      }\n",
      "    }\n",
      "    for (k.outer: int32, 0, 21) {\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner, 2)) < 5), dtype=bool) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (cse_var_2 + j.inner)\n",
      "          compute[cse_var_1] = (compute[cse_var_1] + (A[(k.outer*4)]*B[(((k.outer*40) + cse_var_2) + j.inner)]))\n",
      "        }\n",
      "      }\n",
      "      for (j.inner_1: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner_1, 2)) < 5), dtype=bool) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (cse_var_4 + j.inner_1)\n",
      "          compute[cse_var_3] = (compute[cse_var_3] + (A[((k.outer*4) + 1)]*B[((((k.outer*40) + cse_var_4) + j.inner_1) + 10)]))\n",
      "        }\n",
      "      }\n",
      "      for (j.inner_2: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner_2, 2)) < 5), dtype=bool) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (cse_var_6 + j.inner_2)\n",
      "          compute[cse_var_5] = (compute[cse_var_5] + (A[((k.outer*4) + 2)]*B[((((k.outer*40) + cse_var_6) + j.inner_2) + 20)]))\n",
      "        }\n",
      "      }\n",
      "      for (j.inner_3: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner_3, 2)) < 5), dtype=bool) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (cse_var_8 + j.inner_3)\n",
      "          compute[cse_var_7] = (compute[cse_var_7] + (A[((k.outer*4) + 3)]*B[((((k.outer*40) + cse_var_8) + j.inner_3) + 30)]))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [10], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [840], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [84], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 10], []), B_1: B_3: Buffer(B_2, float32, [84, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [1, 84], [])} {\n",
      "  for (j.outer: int32, 0, 21) {\n",
      "    for (j.inner.init: int32, 0, 4) {\n",
      "      compute[((j.outer*4) + j.inner.init)] = 0f32\n",
      "    }\n",
      "    for (k.outer: int32, 0, 3) {\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        let cse_var_2: int32 = (k.outer*4)\n",
      "        let cse_var_1: int32 = ((j.outer*4) + j.inner)\n",
      "        compute[cse_var_1] = (compute[cse_var_1] + (A[cse_var_2]*B[(((j.outer*40) + (j.inner*10)) + cse_var_2)]))\n",
      "      }\n",
      "      for (j.inner_1: int32, 0, 4) {\n",
      "        let cse_var_4: int32 = (k.outer*4)\n",
      "        let cse_var_3: int32 = ((j.outer*4) + j.inner_1)\n",
      "        compute[cse_var_3] = (compute[cse_var_3] + (A[(cse_var_4 + 1)]*B[((((j.outer*40) + (j.inner_1*10)) + cse_var_4) + 1)]))\n",
      "      }\n",
      "      if @tir.likely((k.outer < 2), dtype=bool) {\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (k.outer*4)\n",
      "          let cse_var_5: int32 = ((j.outer*4) + j.inner_2)\n",
      "          compute[cse_var_5] = (compute[cse_var_5] + (A[(cse_var_6 + 2)]*B[((((j.outer*40) + (j.inner_2*10)) + cse_var_6) + 2)]))\n",
      "        }\n",
      "      }\n",
      "      if @tir.likely((k.outer < 2), dtype=bool) {\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (k.outer*4)\n",
      "          let cse_var_7: int32 = ((j.outer*4) + j.inner_3)\n",
      "          compute[cse_var_7] = (compute[cse_var_7] + (A[(cse_var_8 + 3)]*B[((((j.outer*40) + (j.inner_3*10)) + cse_var_8) + 3)]))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [84], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [10080], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [120], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 84], []), B_1: B_3: Buffer(B_2, float32, [120, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [1, 120], [])} {\n",
      "  for (j.outer: int32, 0, 30) {\n",
      "    for (j.inner.init: int32, 0, 4) {\n",
      "      compute[((j.outer*4) + j.inner.init)] = 0f32\n",
      "    }\n",
      "    for (k.outer: int32, 0, 21) {\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        let cse_var_2: int32 = (k.outer*4)\n",
      "        let cse_var_1: int32 = ((j.outer*4) + j.inner)\n",
      "        compute[cse_var_1] = (compute[cse_var_1] + (A[cse_var_2]*B[(((j.outer*336) + (j.inner*84)) + cse_var_2)]))\n",
      "      }\n",
      "      for (j.inner_1: int32, 0, 4) {\n",
      "        let cse_var_4: int32 = (k.outer*4)\n",
      "        let cse_var_3: int32 = ((j.outer*4) + j.inner_1)\n",
      "        compute[cse_var_3] = (compute[cse_var_3] + (A[(cse_var_4 + 1)]*B[((((j.outer*336) + (j.inner_1*84)) + cse_var_4) + 1)]))\n",
      "      }\n",
      "      for (j.inner_2: int32, 0, 4) {\n",
      "        let cse_var_6: int32 = (k.outer*4)\n",
      "        let cse_var_5: int32 = ((j.outer*4) + j.inner_2)\n",
      "        compute[cse_var_5] = (compute[cse_var_5] + (A[(cse_var_6 + 2)]*B[((((j.outer*336) + (j.inner_2*84)) + cse_var_6) + 2)]))\n",
      "      }\n",
      "      for (j.inner_3: int32, 0, 4) {\n",
      "        let cse_var_8: int32 = (k.outer*4)\n",
      "        let cse_var_7: int32 = ((j.outer*4) + j.inner_3)\n",
      "        compute[cse_var_7] = (compute[cse_var_7] + (A[(cse_var_8 + 3)]*B[((((j.outer*336) + (j.inner_3*84)) + cse_var_8) + 3)]))\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [120], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [30720], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [256], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 120], []), B_1: B_3: Buffer(B_2, float32, [256, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [1, 256], [])} {\n",
      "  for (j.outer: int32, 0, 64) {\n",
      "    for (j.inner.init: int32, 0, 4) {\n",
      "      compute[((j.outer*4) + j.inner.init)] = 0f32\n",
      "    }\n",
      "    for (k.outer: int32, 0, 30) {\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        let cse_var_2: int32 = (k.outer*4)\n",
      "        let cse_var_1: int32 = ((j.outer*4) + j.inner)\n",
      "        compute[cse_var_1] = (compute[cse_var_1] + (A[cse_var_2]*B[(((j.outer*480) + (j.inner*120)) + cse_var_2)]))\n",
      "      }\n",
      "      for (j.inner_1: int32, 0, 4) {\n",
      "        let cse_var_4: int32 = (k.outer*4)\n",
      "        let cse_var_3: int32 = ((j.outer*4) + j.inner_1)\n",
      "        compute[cse_var_3] = (compute[cse_var_3] + (A[(cse_var_4 + 1)]*B[((((j.outer*480) + (j.inner_1*120)) + cse_var_4) + 1)]))\n",
      "      }\n",
      "      for (j.inner_2: int32, 0, 4) {\n",
      "        let cse_var_6: int32 = (k.outer*4)\n",
      "        let cse_var_5: int32 = ((j.outer*4) + j.inner_2)\n",
      "        compute[cse_var_5] = (compute[cse_var_5] + (A[(cse_var_6 + 2)]*B[((((j.outer*480) + (j.inner_2*120)) + cse_var_6) + 2)]))\n",
      "      }\n",
      "      for (j.inner_3: int32, 0, 4) {\n",
      "        let cse_var_8: int32 = (k.outer*4)\n",
      "        let cse_var_7: int32 = ((j.outer*4) + j.inner_3)\n",
      "        compute[cse_var_7] = (compute[cse_var_7] + (A[(cse_var_8 + 3)]*B[((((j.outer*480) + (j.inner_3*120)) + cse_var_8) + 3)]))\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [256], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [120], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [30720], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 256], []), B_1: B_3: Buffer(B_2, float32, [1, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [256, 120], [])} {\n",
      "  for (i.outer: int32, 0, 64) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 30) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*480) + (j.outer*4)) + j.inner.init), 120, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        let cse_var_2: int32 = (j.outer*4)\n",
      "        let cse_var_1: int32 = (((i.outer*480) + cse_var_2) + j.inner)\n",
      "        compute[ramp(cse_var_1, 120, 4)] = (compute[ramp(cse_var_1, 120, 4)] + (A[ramp((i.outer*4), 1, 4)]*broadcast(B[(cse_var_2 + j.inner)], 4)))\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [120], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [84], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [10080], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 120], []), B_1: B_3: Buffer(B_2, float32, [1, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [120, 84], [])} {\n",
      "  for (i.outer: int32, 0, 30) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 21) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*336) + (j.outer*4)) + j.inner.init), 84, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        let cse_var_2: int32 = (j.outer*4)\n",
      "        let cse_var_1: int32 = (((i.outer*336) + cse_var_2) + j.inner)\n",
      "        compute[ramp(cse_var_1, 84, 4)] = (compute[ramp(cse_var_1, 84, 4)] + (A[ramp((i.outer*4), 1, 4)]*broadcast(B[(cse_var_2 + j.inner)], 4)))\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [84], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [10], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [840], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1, 84], []), B_1: B_3: Buffer(B_2, float32, [1, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [84, 10], [])} {\n",
      "  for (i.outer: int32, 0, 21) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 3) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner.init, 2)) < 5), dtype=bool) {\n",
      "          compute[ramp((((i.outer*40) + (j.outer*4)) + j.inner.init), 10, 4)] = broadcast(0f32, 4)\n",
      "        }\n",
      "      }\n",
      "      for (j.inner: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner, 2)) < 5), dtype=bool) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*40) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 10, 4)] = (compute[ramp(cse_var_1, 10, 4)] + (A[ramp((i.outer*4), 1, 4)]*broadcast(B[(cse_var_2 + j.inner)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "Predicted class = 0\n",
      "Actual class = 0\n"
     ]
    }
   ],
   "source": [
    "# visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# pick a random image from the test set\n",
    "idx = np.random.randint(0, test_set[0].shape[0])\n",
    "img = test_set_x[idx:idx+1]\n",
    "# plot the image\n",
    "plt.imshow(img[0][0], cmap=cm.Greys_r)\n",
    "plt.show()\n",
    "\n",
    "# get predictions\n",
    "test_X_val.copyfrom(img)\n",
    "test_y_val.copyfrom(convert_to_one_hot(test_set_y[idx:idx+1]))\n",
    "_, _, _, _, _, _, _, _, _, _, _, _, _, test_y_predicted = executor.run(\n",
    "    feed_dict={\n",
    "        X: test_X_val,\n",
    "        y_: test_y_val,\n",
    "        F1: F1_val,\n",
    "        BN1_gamma: BN1_gamma_val,\n",
    "        BN1_beta: BN1_beta_val,\n",
    "        F2: F2_val,\n",
    "        BN2_gamma: BN2_gamma_val,\n",
    "        BN2_beta: BN2_beta_val,\n",
    "        W1: W1_val,\n",
    "        W2: W2_val,\n",
    "        W3: W3_val,\n",
    "        b1: b1_val,\n",
    "        b2: b2_val,\n",
    "        b3: b3_val},\n",
    "    convert_to_numpy_ret_vals=True);\n",
    "print(\"Predicted class = %d\" % np.argmax(test_y_predicted))\n",
    "print(\"Actual class = %d\" % test_set_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medoflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
