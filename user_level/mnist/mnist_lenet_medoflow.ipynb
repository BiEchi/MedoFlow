{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with LeNet-5\n",
    "\n",
    "This file is extracted from mnist_dlsys.py, with extra code about logging and plotting added."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import six.moves.cPickle as pickle\n",
    "import gzip\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tvm\n",
    "from system_level import autodiff as ad\n",
    "from system_level import tvm_op\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = \"llvm\"\n",
    "tgt_host = \"llvm\"\n",
    "\n",
    "# create context object\n",
    "executor_ctx = tvm.device(tgt, 0)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "def convert_to_one_hot(vals):\n",
    "    \"\"\"Helper method to convert label array to one-hot array.\"\"\"\n",
    "    one_hot_vals = np.zeros((vals.size, 10))\n",
    "    one_hot_vals[np.arange(vals.size), vals] = 1\n",
    "    return one_hot_vals\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and examine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded train_set, valid_set and test_set.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load the dataset\n",
    "Code adapted from http://deeplearning.net/tutorial/code/logistic_sgd.py\n",
    "\n",
    ":type dataset: string\n",
    ":param dataset: the path to the dataset (here MNIST)\n",
    "\"\"\"\n",
    "# Download the MNIST dataset if it is not present\n",
    "dataset = \"mnist.pkl.gz\"\n",
    "\n",
    "data_dir, data_file = os.path.split(dataset)\n",
    "if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "    # Check if dataset is in the data directory.\n",
    "    new_path = os.path.join(\n",
    "        os.path.split(__file__)[0],\n",
    "        dataset\n",
    "    )\n",
    "    if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "        dataset = new_path\n",
    "\n",
    "if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "    from six.moves import urllib\n",
    "    origin = (\n",
    "        'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "    )\n",
    "    print('Downloading data from %s' % origin)\n",
    "    urllib.request.urlretrieve(origin, dataset)\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "# Load the dataset\n",
    "with gzip.open(dataset, 'rb') as f:\n",
    "    try:\n",
    "        train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    except:\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "# train_set, valid_set, test_set format: tuple(input, target)\n",
    "# input is a numpy.ndarray of 2 dimensions (a matrix), np.float32\n",
    "# where each row corresponds to an example. target is a\n",
    "# numpy.ndarray of 1 dimension (vector), np.int64 that has the same length\n",
    "# as the number of rows in the input. It should give the target\n",
    "# to the example with the same index in the input.\n",
    "print('Loaded train_set, valid_set and test_set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(50000, 1, 28, 28)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0].shape)\n",
    "print(train_set[1].shape)\n",
    "\n",
    "# because we use lenet, we need to reshape the data\n",
    "train_set = (train_set[0].reshape((-1, 1, 28, 28)), train_set[1])\n",
    "valid_set = (valid_set[0].reshape((-1, 1, 28, 28)), valid_set[1])\n",
    "test_set = (test_set[0].reshape((-1, 1, 28, 28)), test_set[1])\n",
    "\n",
    "print(train_set[0].shape)\n",
    "print(train_set[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a random sample\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_set[0][0][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the computational graph\n",
    "\n",
    "![](../images/lenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Declaring Weights ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Declaring Weights ===\")\n",
    "\n",
    "F1 = ad.Variable(name=\"F1\") # conv2d kernel\n",
    "BN1_gamma = ad.Variable(name=\"BN1_gamma\") # batch norm\n",
    "BN1_beta = ad.Variable(name=\"BN1_beta\") # batch norm\n",
    "\n",
    "F2 = ad.Variable(name=\"F2\") # conv2d kernel\n",
    "BN2_gamma = ad.Variable(name=\"BN2_gamma\") # batch norm\n",
    "BN2_beta = ad.Variable(name=\"BN2_beta\") # batch norm\n",
    "\n",
    "W1 = ad.Variable(name=\"W1\") # fully connected weight\n",
    "b1 = ad.Variable(name=\"b1\") # fully connected bias\n",
    "\n",
    "W2 = ad.Variable(name=\"W2\") # fully connected weight\n",
    "b2 = ad.Variable(name=\"b2\") # fully connected bias\n",
    "\n",
    "W3 = ad.Variable(name=\"W3\") # fully connected weight\n",
    "b3 = ad.Variable(name=\"b3\") # fully connected bias\n",
    "\n",
    "X = ad.Variable(name=\"X\") # input\n",
    "y_ = ad.Variable(name=\"y_\") # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Constructing Computational Graph ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Constructing Computational Graph ===\")\n",
    "\n",
    "# CNN1: bn(maxpool(relu(conv(X F))))\n",
    "z1 = ad.conv2d_op(X, F1)\n",
    "z2 = ad.relu_op(z1)\n",
    "z3 = ad.maxpool2d_op(z2, pool_size=2, stride=2)\n",
    "z4 = ad.batchnorm2d_op(z3, BN1_gamma, BN1_beta)\n",
    "\n",
    "# CNN2: bn(maxpool(relu(conv(z3, F2))))\n",
    "z5 = ad.conv2d_op(z4, F2)\n",
    "z6 = ad.relu_op(z5)\n",
    "z7 = ad.maxpool2d_op(z6, pool_size=2, stride=2)\n",
    "z8 = ad.batchnorm2d_op(z7, BN2_gamma, BN2_beta)\n",
    "\n",
    "# flatten\n",
    "CHW = (16, 4, 4)\n",
    "z9 = ad.flatten_op(z8, CHW)\n",
    "\n",
    "# mlp: relu(matmul(z7, W1) + b1)\n",
    "z10 = ad.matmul_op(z9, W1)\n",
    "z11 = ad.relu_op(z10 + ad.broadcastto_op(b1, z10))\n",
    "z12 = ad.matmul_op(z11, W2) \n",
    "z13 = ad.relu_op(z12 + ad.broadcastto_op(b2, z12))\n",
    "z14 = ad.matmul_op(z13, W3)\n",
    "y = z14 + ad.broadcastto_op(b3, z14)\n",
    "\n",
    "# softmax & cross entropy\n",
    "loss = ad.softmaxcrossentropy_op(y, y_)\n",
    "\n",
    "grad_F1, grad_BN1_gamma, grad_BN1_beta, grad_F2, grad_BN2_gamma, grad_BN2_beta, grad_W1, grad_W2, grad_W3, grad_b1, grad_b2, grad_b3 = ad.gradients(\n",
    "    loss, [F1, BN1_gamma, BN1_beta, F2, BN2_gamma, BN2_beta, W1, W2, W3, b1, b2, b3])\n",
    "     \n",
    "executor = ad.Executor(\n",
    "    [loss, grad_F1, grad_BN1_gamma, grad_BN1_beta, grad_F2, grad_BN2_gamma, grad_BN2_beta, grad_W1, grad_W2, grad_W3, grad_b1, grad_b2, grad_b3, y],\n",
    "    ctx=executor_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initializing Weights ===\n",
      "Start training loop...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Initializing Weights ===\")\n",
    "\n",
    "# Read input data\n",
    "train_set_x, train_set_y = train_set\n",
    "valid_set_x, valid_set_y = valid_set\n",
    "test_set_x, test_set_y = test_set\n",
    "# Set up minibatch\n",
    "batch_size = 64\n",
    "n_train_batches = train_set_x.shape[0] // batch_size\n",
    "n_valid_batches = valid_set_x.shape[0] // batch_size\n",
    "\n",
    "print(\"Start training loop...\")\n",
    "\n",
    "# Initialize parameters\n",
    "rand = np.random.RandomState(seed=42)\n",
    "# n*1*28*28\n",
    "F1_val = rand.normal(scale=0.1, size=(6, 1, 5, 5)).astype(np.float32)\n",
    "# n*6*24*24\n",
    "# maxpool\n",
    "# n*6*12*12\n",
    "BN1_gamma_val = np.ones(shape=(1, 6, 1, 1)).astype(np.float32)\n",
    "BN1_beta_val = np.zeros(shape=(1, 6, 1, 1)).astype(np.float32)\n",
    "\n",
    "F2_val = rand.normal(scale=0.1, size=(16, 6, 5, 5)).astype(np.float32)\n",
    "# n*16*8*8\n",
    "# maxpool\n",
    "# n*16*4*4\n",
    "BN2_gamma_val = np.ones(shape=(1, 16, 1, 1)).astype(np.float32)\n",
    "BN2_beta_val = np.zeros(shape=(1, 16, 1, 1)).astype(np.float32)\n",
    "\n",
    "W1_val = rand.normal(scale=0.1, size=(16*4*4, 120)).astype(np.float32)\n",
    "b1_val = rand.normal(scale=0.1, size=(120)).astype(np.float32)\n",
    "\n",
    "W2_val = rand.normal(scale=0.1, size=(120, 84)).astype(np.float32)\n",
    "b2_val = rand.normal(scale=0.1, size=(84)).astype(np.float32)\n",
    "\n",
    "W3_val = rand.normal(scale=0.1, size=(84, 10)).astype(np.float32)\n",
    "b3_val = rand.normal(scale=0.1, size=(10)).astype(np.float32)\n",
    "\n",
    "X_val = np.empty(shape=(batch_size, 1, 28, 28), dtype=np.float32)\n",
    "y_val = np.empty(shape=(batch_size, 10), dtype=np.float32)\n",
    "\n",
    "valid_X_val = np.empty(shape=(batch_size, 1, 28, 28), dtype=np.float32)\n",
    "valid_y_val = np.empty(shape=(batch_size, 10), dtype=np.float32)\n",
    "\n",
    "test_X_val = np.empty(shape=(1, 1, 28, 28), dtype=np.float32)\n",
    "test_y_val = np.empty(shape=(1, 10), dtype=np.float32)\n",
    "\n",
    "# wrap with tvm.nd.array\n",
    "F1_val = tvm.nd.array(F1_val)\n",
    "BN1_gamma_val = tvm.nd.array(BN1_gamma_val)\n",
    "BN1_beta_val = tvm.nd.array(BN1_beta_val)\n",
    "F2_val = tvm.nd.array(F2_val)\n",
    "BN2_gamma_val = tvm.nd.array(BN2_gamma_val)\n",
    "BN2_beta_val = tvm.nd.array(BN2_beta_val)\n",
    "W1_val = tvm.nd.array(W1_val)\n",
    "b1_val = tvm.nd.array(b1_val)\n",
    "W2_val = tvm.nd.array(W2_val)\n",
    "b2_val = tvm.nd.array(b2_val)\n",
    "W3_val = tvm.nd.array(W3_val)\n",
    "b3_val = tvm.nd.array(b3_val)\n",
    "\n",
    "X_val = tvm.nd.array(X_val)\n",
    "y_val = tvm.nd.array(y_val)\n",
    "valid_X_val = tvm.nd.array(valid_X_val)\n",
    "valid_y_val = tvm.nd.array(valid_y_val)\n",
    "test_X_val = tvm.nd.array(test_X_val)\n",
    "test_y_val = tvm.nd.array(test_y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "lr = 0.0005\n",
    "# JIT compile sgd update ops\n",
    "F1_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    F1_val.shape, lr, tgt, tgt_host, \"F1_sgd_update\")\n",
    "BN1_gamma_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    BN1_gamma_val.shape, lr, tgt, tgt_host, \"BN1_gamma_sgd_update\")\n",
    "BN1_beta_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    BN1_beta_val.shape, lr, tgt, tgt_host, \"BN1_beta_sgd_update\")\n",
    "\n",
    "F2_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    F2_val.shape, lr, tgt, tgt_host, \"F2_sgd_update\")\n",
    "BN2_gamma_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    BN2_gamma_val.shape, lr, tgt, tgt_host, \"BN2_gamma_sgd_update\")\n",
    "BN2_beta_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    BN2_beta_val.shape, lr, tgt, tgt_host, \"BN2_beta_sgd_update\")\n",
    "\n",
    "W1_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    W1_val.shape, lr, tgt, tgt_host, \"W1_sgd_update\")\n",
    "W2_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    W2_val.shape, lr, tgt, tgt_host, \"W2_sgd_update\")\n",
    "W3_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    W3_val.shape, lr, tgt, tgt_host, \"W3_sgd_update\")\n",
    "b1_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    b1_val.shape, lr, tgt, tgt_host, \"b1_sgd_update\")\n",
    "b2_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    b2_val.shape, lr, tgt, tgt_host, \"b2_sgd_update\")\n",
    "b3_sgd_update_func = tvm_op.make_sgd_update(\n",
    "    b3_val.shape, lr, tgt, tgt_host, \"b3_sgd_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** EPOCH 1 *****\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [16384], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [30720], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [7680], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 256], []), B_1: B_3: Buffer(B_2, float32, [256, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 120], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 30) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*480) + (j.outer*4)) + j.inner.init), 120, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 64) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*480) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 120, 4)] = (compute[ramp(cse_var_1, 120, 4)] + (A[ramp(((i.outer*1024) + (k.outer*4)), 256, 4)]*broadcast(B[(((k.outer*480) + cse_var_2) + j.inner)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*480) + cse_var_4) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 120, 4)] = (compute[ramp(cse_var_3, 120, 4)] + (A[ramp((((i.outer*1024) + (k.outer*4)) + 1), 256, 4)]*broadcast(B[((((k.outer*480) + cse_var_4) + j.inner_1) + 120)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*480) + cse_var_6) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 120, 4)] = (compute[ramp(cse_var_5, 120, 4)] + (A[ramp((((i.outer*1024) + (k.outer*4)) + 2), 256, 4)]*broadcast(B[((((k.outer*480) + cse_var_6) + j.inner_2) + 240)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*480) + cse_var_8) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 120, 4)] = (compute[ramp(cse_var_7, 120, 4)] + (A[ramp((((i.outer*1024) + (k.outer*4)) + 3), 256, 4)]*broadcast(B[((((k.outer*480) + cse_var_8) + j.inner_3) + 360)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [7680], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [10080], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [5376], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 120], []), B_1: B_3: Buffer(B_2, float32, [120, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 84], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 21) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*336) + (j.outer*4)) + j.inner.init), 84, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 30) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*336) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 84, 4)] = (compute[ramp(cse_var_1, 84, 4)] + (A[ramp(((i.outer*480) + (k.outer*4)), 120, 4)]*broadcast(B[(((k.outer*336) + cse_var_2) + j.inner)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*336) + cse_var_4) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 84, 4)] = (compute[ramp(cse_var_3, 84, 4)] + (A[ramp((((i.outer*480) + (k.outer*4)) + 1), 120, 4)]*broadcast(B[((((k.outer*336) + cse_var_4) + j.inner_1) + 84)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*336) + cse_var_6) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 84, 4)] = (compute[ramp(cse_var_5, 84, 4)] + (A[ramp((((i.outer*480) + (k.outer*4)) + 2), 120, 4)]*broadcast(B[((((k.outer*336) + cse_var_6) + j.inner_2) + 168)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*336) + cse_var_8) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 84, 4)] = (compute[ramp(cse_var_7, 84, 4)] + (A[ramp((((i.outer*480) + (k.outer*4)) + 3), 120, 4)]*broadcast(B[((((k.outer*336) + cse_var_8) + j.inner_3) + 252)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [5376], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [840], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [640], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 84], []), B_1: B_3: Buffer(B_2, float32, [84, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 10], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 3) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner.init, 2)) < 5), dtype=bool) {\n",
      "          compute[ramp((((i.outer*40) + (j.outer*4)) + j.inner.init), 10, 4)] = broadcast(0f32, 4)\n",
      "        }\n",
      "      }\n",
      "      for (k.outer: int32, 0, 21) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_2: int32 = (j.outer*4)\n",
      "            let cse_var_1: int32 = (((i.outer*40) + cse_var_2) + j.inner)\n",
      "            compute[ramp(cse_var_1, 10, 4)] = (compute[ramp(cse_var_1, 10, 4)] + (A[ramp(((i.outer*336) + (k.outer*4)), 84, 4)]*broadcast(B[(((k.outer*40) + cse_var_2) + j.inner)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_1, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_4: int32 = (j.outer*4)\n",
      "            let cse_var_3: int32 = (((i.outer*40) + cse_var_4) + j.inner_1)\n",
      "            compute[ramp(cse_var_3, 10, 4)] = (compute[ramp(cse_var_3, 10, 4)] + (A[ramp((((i.outer*336) + (k.outer*4)) + 1), 84, 4)]*broadcast(B[((((k.outer*40) + cse_var_4) + j.inner_1) + 10)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_2, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_6: int32 = (j.outer*4)\n",
      "            let cse_var_5: int32 = (((i.outer*40) + cse_var_6) + j.inner_2)\n",
      "            compute[ramp(cse_var_5, 10, 4)] = (compute[ramp(cse_var_5, 10, 4)] + (A[ramp((((i.outer*336) + (k.outer*4)) + 2), 84, 4)]*broadcast(B[((((k.outer*40) + cse_var_6) + j.inner_2) + 20)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_3, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_8: int32 = (j.outer*4)\n",
      "            let cse_var_7: int32 = (((i.outer*40) + cse_var_8) + j.inner_3)\n",
      "            compute[ramp(cse_var_7, 10, 4)] = (compute[ramp(cse_var_7, 10, 4)] + (A[ramp((((i.outer*336) + (k.outer*4)) + 3), 84, 4)]*broadcast(B[((((k.outer*40) + cse_var_8) + j.inner_3) + 30)], 4)))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [640], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [840], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [5376], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 10], []), B_1: B_3: Buffer(B_2, float32, [84, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 84], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 21) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*336) + (j.outer*4)) + j.inner.init), 84, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 3) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (k.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*336) + (j.outer*4)) + j.inner)\n",
      "          compute[ramp(cse_var_1, 84, 4)] = (compute[ramp(cse_var_1, 84, 4)] + (A[ramp(((i.outer*40) + cse_var_2), 10, 4)]*broadcast(B[(((j.outer*40) + (j.inner*10)) + cse_var_2)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (k.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*336) + (j.outer*4)) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 84, 4)] = (compute[ramp(cse_var_3, 84, 4)] + (A[ramp((((i.outer*40) + cse_var_4) + 1), 10, 4)]*broadcast(B[((((j.outer*40) + (j.inner_1*10)) + cse_var_4) + 1)], 4)))\n",
      "        }\n",
      "        if @tir.likely((k.outer < 2), dtype=bool) {\n",
      "          for (j.inner_2: int32, 0, 4) {\n",
      "            let cse_var_6: int32 = (k.outer*4)\n",
      "            let cse_var_5: int32 = (((i.outer*336) + (j.outer*4)) + j.inner_2)\n",
      "            compute[ramp(cse_var_5, 84, 4)] = (compute[ramp(cse_var_5, 84, 4)] + (A[ramp((((i.outer*40) + cse_var_6) + 2), 10, 4)]*broadcast(B[((((j.outer*40) + (j.inner_2*10)) + cse_var_6) + 2)], 4)))\n",
      "          }\n",
      "        }\n",
      "        if @tir.likely((k.outer < 2), dtype=bool) {\n",
      "          for (j.inner_3: int32, 0, 4) {\n",
      "            let cse_var_8: int32 = (k.outer*4)\n",
      "            let cse_var_7: int32 = (((i.outer*336) + (j.outer*4)) + j.inner_3)\n",
      "            compute[ramp(cse_var_7, 84, 4)] = (compute[ramp(cse_var_7, 84, 4)] + (A[ramp((((i.outer*40) + cse_var_8) + 3), 10, 4)]*broadcast(B[((((j.outer*40) + (j.inner_3*10)) + cse_var_8) + 3)], 4)))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [5376], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [10080], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [7680], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 84], []), B_1: B_3: Buffer(B_2, float32, [120, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 120], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 30) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*480) + (j.outer*4)) + j.inner.init), 120, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 21) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (k.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*480) + (j.outer*4)) + j.inner)\n",
      "          compute[ramp(cse_var_1, 120, 4)] = (compute[ramp(cse_var_1, 120, 4)] + (A[ramp(((i.outer*336) + cse_var_2), 84, 4)]*broadcast(B[(((j.outer*336) + (j.inner*84)) + cse_var_2)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (k.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*480) + (j.outer*4)) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 120, 4)] = (compute[ramp(cse_var_3, 120, 4)] + (A[ramp((((i.outer*336) + cse_var_4) + 1), 84, 4)]*broadcast(B[((((j.outer*336) + (j.inner_1*84)) + cse_var_4) + 1)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (k.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*480) + (j.outer*4)) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 120, 4)] = (compute[ramp(cse_var_5, 120, 4)] + (A[ramp((((i.outer*336) + cse_var_6) + 2), 84, 4)]*broadcast(B[((((j.outer*336) + (j.inner_2*84)) + cse_var_6) + 2)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (k.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*480) + (j.outer*4)) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 120, 4)] = (compute[ramp(cse_var_7, 120, 4)] + (A[ramp((((i.outer*336) + cse_var_8) + 3), 84, 4)]*broadcast(B[((((j.outer*336) + (j.inner_3*84)) + cse_var_8) + 3)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [7680], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [30720], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [16384], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 120], []), B_1: B_3: Buffer(B_2, float32, [256, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [64, 256], [])} {\n",
      "  for (i.outer: int32, 0, 16) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 64) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*1024) + (j.outer*4)) + j.inner.init), 256, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 30) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (k.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*1024) + (j.outer*4)) + j.inner)\n",
      "          compute[ramp(cse_var_1, 256, 4)] = (compute[ramp(cse_var_1, 256, 4)] + (A[ramp(((i.outer*480) + cse_var_2), 120, 4)]*broadcast(B[(((j.outer*480) + (j.inner*120)) + cse_var_2)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (k.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*1024) + (j.outer*4)) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 256, 4)] = (compute[ramp(cse_var_3, 256, 4)] + (A[ramp((((i.outer*480) + cse_var_4) + 1), 120, 4)]*broadcast(B[((((j.outer*480) + (j.inner_1*120)) + cse_var_4) + 1)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (k.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*1024) + (j.outer*4)) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 256, 4)] = (compute[ramp(cse_var_5, 256, 4)] + (A[ramp((((i.outer*480) + cse_var_6) + 2), 120, 4)]*broadcast(B[((((j.outer*480) + (j.inner_2*120)) + cse_var_6) + 2)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (k.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*1024) + (j.outer*4)) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 256, 4)] = (compute[ramp(cse_var_7, 256, 4)] + (A[ramp((((i.outer*480) + cse_var_8) + 3), 120, 4)]*broadcast(B[((((j.outer*480) + (j.inner_3*120)) + cse_var_8) + 3)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [16384], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [7680], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [30720], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 256], []), B_1: B_3: Buffer(B_2, float32, [64, 120], []), compute_1: compute_3: Buffer(compute_2, float32, [256, 120], [])} {\n",
      "  for (i.outer: int32, 0, 64) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 30) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*480) + (j.outer*4)) + j.inner.init), 120, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 16) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*480) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 120, 4)] = (compute[ramp(cse_var_1, 120, 4)] + (A[ramp(((k.outer*1024) + (i.outer*4)), 1, 4)]*broadcast(B[(((k.outer*480) + cse_var_2) + j.inner)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*480) + cse_var_4) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 120, 4)] = (compute[ramp(cse_var_3, 120, 4)] + (A[ramp((((k.outer*1024) + (i.outer*4)) + 256), 1, 4)]*broadcast(B[((((k.outer*480) + cse_var_4) + j.inner_1) + 120)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*480) + cse_var_6) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 120, 4)] = (compute[ramp(cse_var_5, 120, 4)] + (A[ramp((((k.outer*1024) + (i.outer*4)) + 512), 1, 4)]*broadcast(B[((((k.outer*480) + cse_var_6) + j.inner_2) + 240)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*480) + cse_var_8) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 120, 4)] = (compute[ramp(cse_var_7, 120, 4)] + (A[ramp((((k.outer*1024) + (i.outer*4)) + 768), 1, 4)]*broadcast(B[((((k.outer*480) + cse_var_8) + j.inner_3) + 360)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [7680], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [5376], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [10080], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 120], []), B_1: B_3: Buffer(B_2, float32, [64, 84], []), compute_1: compute_3: Buffer(compute_2, float32, [120, 84], [])} {\n",
      "  for (i.outer: int32, 0, 30) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 21) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        compute[ramp((((i.outer*336) + (j.outer*4)) + j.inner.init), 84, 4)] = broadcast(0f32, 4)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 16) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          let cse_var_2: int32 = (j.outer*4)\n",
      "          let cse_var_1: int32 = (((i.outer*336) + cse_var_2) + j.inner)\n",
      "          compute[ramp(cse_var_1, 84, 4)] = (compute[ramp(cse_var_1, 84, 4)] + (A[ramp(((k.outer*480) + (i.outer*4)), 1, 4)]*broadcast(B[(((k.outer*336) + cse_var_2) + j.inner)], 4)))\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          let cse_var_4: int32 = (j.outer*4)\n",
      "          let cse_var_3: int32 = (((i.outer*336) + cse_var_4) + j.inner_1)\n",
      "          compute[ramp(cse_var_3, 84, 4)] = (compute[ramp(cse_var_3, 84, 4)] + (A[ramp((((k.outer*480) + (i.outer*4)) + 120), 1, 4)]*broadcast(B[((((k.outer*336) + cse_var_4) + j.inner_1) + 84)], 4)))\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          let cse_var_6: int32 = (j.outer*4)\n",
      "          let cse_var_5: int32 = (((i.outer*336) + cse_var_6) + j.inner_2)\n",
      "          compute[ramp(cse_var_5, 84, 4)] = (compute[ramp(cse_var_5, 84, 4)] + (A[ramp((((k.outer*480) + (i.outer*4)) + 240), 1, 4)]*broadcast(B[((((k.outer*336) + cse_var_6) + j.inner_2) + 168)], 4)))\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          let cse_var_8: int32 = (j.outer*4)\n",
      "          let cse_var_7: int32 = (((i.outer*336) + cse_var_8) + j.inner_3)\n",
      "          compute[ramp(cse_var_7, 84, 4)] = (compute[ramp(cse_var_7, 84, 4)] + (A[ramp((((k.outer*480) + (i.outer*4)) + 360), 1, 4)]*broadcast(B[((((k.outer*336) + cse_var_8) + j.inner_3) + 252)], 4)))\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "@main = primfn(A_1: handle, B_1: handle, compute_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [5376], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [640], []),\n",
      "             compute: Buffer(compute_2: Pointer(float32), float32, [840], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, compute_1: compute}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [64, 84], []), B_1: B_3: Buffer(B_2, float32, [64, 10], []), compute_1: compute_3: Buffer(compute_2, float32, [84, 10], [])} {\n",
      "  for (i.outer: int32, 0, 21) \"parallel\" {\n",
      "    for (j.outer: int32, 0, 3) {\n",
      "      for (j.inner.init: int32, 0, 4) {\n",
      "        if @tir.likely((((j.outer*2) + floordiv(j.inner.init, 2)) < 5), dtype=bool) {\n",
      "          compute[ramp((((i.outer*40) + (j.outer*4)) + j.inner.init), 10, 4)] = broadcast(0f32, 4)\n",
      "        }\n",
      "      }\n",
      "      for (k.outer: int32, 0, 16) {\n",
      "        for (j.inner: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_2: int32 = (j.outer*4)\n",
      "            let cse_var_1: int32 = (((i.outer*40) + cse_var_2) + j.inner)\n",
      "            compute[ramp(cse_var_1, 10, 4)] = (compute[ramp(cse_var_1, 10, 4)] + (A[ramp(((k.outer*336) + (i.outer*4)), 1, 4)]*broadcast(B[(((k.outer*40) + cse_var_2) + j.inner)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_1: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_1, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_4: int32 = (j.outer*4)\n",
      "            let cse_var_3: int32 = (((i.outer*40) + cse_var_4) + j.inner_1)\n",
      "            compute[ramp(cse_var_3, 10, 4)] = (compute[ramp(cse_var_3, 10, 4)] + (A[ramp((((k.outer*336) + (i.outer*4)) + 84), 1, 4)]*broadcast(B[((((k.outer*40) + cse_var_4) + j.inner_1) + 10)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_2: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_2, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_6: int32 = (j.outer*4)\n",
      "            let cse_var_5: int32 = (((i.outer*40) + cse_var_6) + j.inner_2)\n",
      "            compute[ramp(cse_var_5, 10, 4)] = (compute[ramp(cse_var_5, 10, 4)] + (A[ramp((((k.outer*336) + (i.outer*4)) + 168), 1, 4)]*broadcast(B[((((k.outer*40) + cse_var_6) + j.inner_2) + 20)], 4)))\n",
      "          }\n",
      "        }\n",
      "        for (j.inner_3: int32, 0, 4) {\n",
      "          if @tir.likely((((j.outer*2) + floordiv(j.inner_3, 2)) < 5), dtype=bool) {\n",
      "            let cse_var_8: int32 = (j.outer*4)\n",
      "            let cse_var_7: int32 = (((i.outer*40) + cse_var_8) + j.inner_3)\n",
      "            compute[ramp(cse_var_7, 10, 4)] = (compute[ramp(cse_var_7, 10, 4)] + (A[ramp((((k.outer*336) + (i.outer*4)) + 252), 1, 4)]*broadcast(B[((((k.outer*40) + cse_var_8) + j.inner_3) + 30)], 4)))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "accuracy on training set:  0.9325184058898848\n",
      "accuracy on valid set:  0.9322916666666666\n",
      "epoch 1 loss = 0.2155\n",
      "epoch 1 completed. loss = 0.158513; Time taken this epoch = 1719.265538 s\n",
      "***** EPOCH 2 *****\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m X_val\u001b[39m.\u001b[39mcopyfrom(train_set_x[minibatch_start:minibatch_end])\n\u001b[1;32m     15\u001b[0m y_val\u001b[39m.\u001b[39mcopyfrom(\n\u001b[1;32m     16\u001b[0m     convert_to_one_hot(train_set_y[minibatch_start:minibatch_end]))\n\u001b[1;32m     18\u001b[0m _, grad_F1_val, grad_BN1_gamma_val, grad_BN1_beta_val, \\\n\u001b[1;32m     19\u001b[0m     grad_F2_val, grad_BN2_gamma_val, grad_BN2_beta_val, \\\n\u001b[1;32m     20\u001b[0m     grad_W1_val, grad_W2_val, grad_W3_val, \\\n\u001b[0;32m---> 21\u001b[0m     grad_b1_val, grad_b2_val, grad_b3_val, _ \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     22\u001b[0m         feed_dict\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     23\u001b[0m             X: X_val,\n\u001b[1;32m     24\u001b[0m             y_: y_val,\n\u001b[1;32m     25\u001b[0m             F1: F1_val,\n\u001b[1;32m     26\u001b[0m             BN1_gamma: BN1_gamma_val,\n\u001b[1;32m     27\u001b[0m             BN1_beta: BN1_beta_val,\n\u001b[1;32m     28\u001b[0m             F2: F2_val,\n\u001b[1;32m     29\u001b[0m             BN2_gamma: BN2_gamma_val,\n\u001b[1;32m     30\u001b[0m             BN2_beta: BN2_beta_val,\n\u001b[1;32m     31\u001b[0m             W1: W1_val,\n\u001b[1;32m     32\u001b[0m             W2: W2_val,\n\u001b[1;32m     33\u001b[0m             W3: W3_val,\n\u001b[1;32m     34\u001b[0m             b1: b1_val,\n\u001b[1;32m     35\u001b[0m             b2: b2_val,\n\u001b[1;32m     36\u001b[0m             b3: b3_val})\n\u001b[1;32m     37\u001b[0m \u001b[39m# SGD update\u001b[39;00m\n\u001b[1;32m     38\u001b[0m F1_sgd_update_func(F1_val, grad_F1_val, F1_val)\n",
      "File \u001b[0;32m~/Desktop/Courses/Course23SP/MedoFlow-dev/framework/user_level/mnist/../../system_level/autodiff.py:1092\u001b[0m, in \u001b[0;36mExecutor.run\u001b[0;34m(self, feed_dict, convert_to_numpy_ret_vals, return_hidden)\u001b[0m\n\u001b[1;32m   1090\u001b[0m     node_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_to_arr_map[node]\n\u001b[1;32m   1091\u001b[0m     \u001b[39m# node_val is modified in-place\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m     node\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m   1093\u001b[0m         node, input_vals, node_val, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_to_compiled_func[node])\n\u001b[1;32m   1094\u001b[0m     node_to_val_map[node] \u001b[39m=\u001b[39m node_val\n\u001b[1;32m   1095\u001b[0m \u001b[39m# Collect node values.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Courses/Course23SP/MedoFlow-dev/framework/user_level/mnist/../../system_level/autodiff.py:343\u001b[0m, in \u001b[0;36mConv2dGradientXOp.compute\u001b[0;34m(self, node, input_vals, output_val, compiled_func)\u001b[0m\n\u001b[1;32m    341\u001b[0m pad \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    342\u001b[0m stride \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 343\u001b[0m output_val \u001b[39m=\u001b[39m np_conv2d_grad_x(dout, x, w, pad, stride)\n\u001b[1;32m    344\u001b[0m output_val \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39mnd\u001b[39m.\u001b[39marray(output_val)\n",
      "File \u001b[0;32m~/Desktop/Courses/Course23SP/MedoFlow-dev/framework/user_level/mnist/../../system_level/autodiff.py:1274\u001b[0m, in \u001b[0;36mnp_conv2d_grad_x\u001b[0;34m(dout, x, w, pad, stride)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                 w1 \u001b[39m=\u001b[39m j \u001b[39m*\u001b[39m stride\n\u001b[1;32m   1273\u001b[0m                 w2 \u001b[39m=\u001b[39m j \u001b[39m*\u001b[39m stride \u001b[39m+\u001b[39m S\n\u001b[0;32m-> 1274\u001b[0m                 dx[n, :, h1:h2, w1:w2] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m w[m,:,:,:] \u001b[39m*\u001b[39m dout[n,m,i,j]\n\u001b[1;32m   1276\u001b[0m \u001b[39mreturn\u001b[39;00m dx\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_measurements = []\n",
    "train_acc_values = []\n",
    "val_acc_values = []\n",
    "loss_values = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    print(f\"***** EPOCH {i+1} *****\")\n",
    "    \n",
    "    # train on train set\n",
    "    start_time = time.time()\n",
    "    for minibatch_index in range(n_train_batches):\n",
    "        minibatch_start = minibatch_index * batch_size\n",
    "        minibatch_end = (minibatch_index + 1) * batch_size\n",
    "        X_val.copyfrom(train_set_x[minibatch_start:minibatch_end])\n",
    "        y_val.copyfrom(\n",
    "            convert_to_one_hot(train_set_y[minibatch_start:minibatch_end]))\n",
    "        \n",
    "        _, grad_F1_val, grad_BN1_gamma_val, grad_BN1_beta_val, \\\n",
    "            grad_F2_val, grad_BN2_gamma_val, grad_BN2_beta_val, \\\n",
    "            grad_W1_val, grad_W2_val, grad_W3_val, \\\n",
    "            grad_b1_val, grad_b2_val, grad_b3_val, _ = executor.run(\n",
    "                feed_dict={\n",
    "                    X: X_val,\n",
    "                    y_: y_val,\n",
    "                    F1: F1_val,\n",
    "                    BN1_gamma: BN1_gamma_val,\n",
    "                    BN1_beta: BN1_beta_val,\n",
    "                    F2: F2_val,\n",
    "                    BN2_gamma: BN2_gamma_val,\n",
    "                    BN2_beta: BN2_beta_val,\n",
    "                    W1: W1_val,\n",
    "                    W2: W2_val,\n",
    "                    W3: W3_val,\n",
    "                    b1: b1_val,\n",
    "                    b2: b2_val,\n",
    "                    b3: b3_val})\n",
    "        # SGD update\n",
    "        F1_sgd_update_func(F1_val, grad_F1_val, F1_val)\n",
    "        BN1_gamma_sgd_update_func(BN1_gamma_val, grad_BN1_gamma_val, BN1_gamma_val)\n",
    "        BN1_beta_sgd_update_func(BN1_beta_val, grad_BN1_beta_val, BN1_beta_val)\n",
    "        F2_sgd_update_func(F2_val, grad_F2_val, F2_val)\n",
    "        BN2_gamma_sgd_update_func(BN2_gamma_val, grad_BN2_gamma_val, BN2_gamma_val)\n",
    "        BN2_beta_sgd_update_func(BN2_beta_val, grad_BN2_beta_val, BN2_beta_val)\n",
    "        W1_sgd_update_func(W1_val, grad_W1_val, W1_val)\n",
    "        W2_sgd_update_func(W2_val, grad_W2_val, W2_val)\n",
    "        W3_sgd_update_func(W3_val, grad_W3_val, W3_val)\n",
    "        b1_sgd_update_func(b1_val, grad_b1_val, b1_val)\n",
    "        b2_sgd_update_func(b2_val, grad_b2_val, b2_val)\n",
    "        b3_sgd_update_func(b3_val, grad_b3_val, b3_val)\n",
    "    \n",
    "    # eval on train set\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    loss_sum = 0\n",
    "    batch_num = 0\n",
    "    for minibatch_index in range(n_train_batches):\n",
    "        minibatch_start = minibatch_index * batch_size\n",
    "        minibatch_end = (minibatch_index + 1) * batch_size\n",
    "        X_val.copyfrom(train_set_x[minibatch_start:minibatch_end])\n",
    "        y_val.copyfrom(\n",
    "            convert_to_one_hot(train_set_y[minibatch_start:minibatch_end]))\n",
    "        loss_val, _, _, _, _, _, _, _, _, _, _, _, _, y_pred = executor.run(\n",
    "            feed_dict={\n",
    "                X: X_val,\n",
    "                y_: y_val,\n",
    "                F1: F1_val,\n",
    "                BN1_gamma: BN1_gamma_val,\n",
    "                BN1_beta: BN1_beta_val,\n",
    "                F2: F2_val,\n",
    "                BN2_gamma: BN2_gamma_val,\n",
    "                BN2_beta: BN2_beta_val,\n",
    "                W1: W1_val,\n",
    "                W2: W2_val,\n",
    "                W3: W3_val,\n",
    "                b1: b1_val,\n",
    "                b2: b2_val,\n",
    "                b3: b3_val})\n",
    "        train_correct += np.sum(y_pred.asnumpy().argmax(axis=1) == train_set_y[minibatch_start:minibatch_end])\n",
    "        train_total += minibatch_end - minibatch_start\n",
    "        loss_sum += loss_val.asnumpy()[0].astype(np.float64)\n",
    "        batch_num += 1\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_values.append(train_acc)\n",
    "    print(\"accuracy on training set: \", train_acc)\n",
    "    \n",
    "    # eval on valid set\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    for minibatch_index in range(n_valid_batches):\n",
    "        minibatch_start = minibatch_index * batch_size\n",
    "        minibatch_end = (minibatch_index + 1) * batch_size\n",
    "        X_val.copyfrom(valid_set_x[minibatch_start:minibatch_end])\n",
    "        y_val.copyfrom(\n",
    "            convert_to_one_hot(valid_set_y[minibatch_start:minibatch_end]))\n",
    "        _, _, _, _, _, _, _, _, _, _, _, _, _, y_pred = executor.run(\n",
    "            feed_dict={\n",
    "                X: X_val, \n",
    "                y_: y_val, \n",
    "                F1: F1_val, \n",
    "                BN1_gamma: BN1_gamma_val, \n",
    "                BN1_beta: BN1_beta_val, \n",
    "                F2: F2_val, \n",
    "                BN2_gamma: BN2_gamma_val, \n",
    "                BN2_beta: BN2_beta_val, \n",
    "                W1: W1_val, \n",
    "                W2: W2_val, \n",
    "                W3: W3_val, \n",
    "                b1: b1_val, \n",
    "                b2: b2_val, \n",
    "                b3: b3_val})\n",
    "        val_correct += np.sum(y_pred.asnumpy().argmax(axis=1) == valid_set_y[minibatch_start:minibatch_end])\n",
    "        val_total += minibatch_end - minibatch_start\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_values.append(val_acc)\n",
    "    print(\"accuracy on valid set: \", val_acc)\n",
    "    \n",
    "    average_loss = loss_sum / batch_num\n",
    "    print(f\"epoch {i+1} loss = {average_loss:.4f}\")\n",
    "    loss_values.append(average_loss)\n",
    "    time_measurements.append(time.time() - start_time)\n",
    "    \n",
    "print(\"Average Time per Training Epoch = %f s\" % np.mean(time_measurements))\n",
    "# w/o batchnorm: [0.0832, 0.261, 0.1037, 0.3641, 0.2317, 0.1784]\n",
    "# w/ batchnorm: [0.0861, 0.94, 0.954, 0.9588, 0.9637, 0.9655, 0.9666, 0.9672, 0.968, 0.9694]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_acc_values = [] val_acc_values = [] loss_values = [] to a json file\n",
    "import json\n",
    "with open(\"results/medoflow_mlp.json\" , \"w\") as f:\n",
    "    json.dump({\"train_acc\": train_acc_values, \n",
    "                \"val_acc\": val_acc_values,\n",
    "                \"loss\": loss_values,\n",
    "                \"time\": time_measurements}, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAGwCAYAAABxbMuTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJKElEQVR4nO3deVxV1f7/8fcBZBLBWQbBCXO6CqVidAfnUMtw6GZmgUN6LYfKSrNMTb9FpdckLetmydVyzCHvz9IUs9JMTcJUUku9aUxOCUgyCOv3R1/PtxODomwRfT0fj/O4nrXX3vuz17XOu7XX2cdmjDECAABAuXOq6AIAAABuVAQtAAAAixC0AAAALELQAgAAsAhBCwAAwCIELQAAAIsQtAAAACziUtEF3MwKCwuVkpKiatWqyWazVXQ5AADgMhhjlJWVJX9/fzk5lT5nRdCqQCkpKQoMDKzoMgAAwBU4fvy46tevX2ofglYFqlatmqTf/o/y9vau4GoAAMDlyMzMVGBgoP1zvDQErQp08Xaht7c3QQsAgErmcpb9sBgeAADAIgQtAAAAixC0AAAALMIaLQDAFSsoKFB+fn5FlwGUO1dX10s+uuFyELQAAGVmjFFaWprOnj1b0aUAlnByclKjRo3k6up6VcchaAEAyuxiyKpbt648PT156DJuKBcfKJ6amqqgoKCr+vtN0AIAlElBQYE9ZNWqVauiywEsUadOHaWkpOjChQuqUqXKFR+HxfAAgDK5uCbL09OzgisBrHPxlmFBQcFVHYegBQC4ItwuxI2svP5+E7QAAAAsQtACAACwCEELAICr0LBhQ82ePfuy+2/ZskU2m41HY9wkCFoAgJuCzWYr9TV16tQrOu6uXbs0YsSIy+5/xx13KDU1VT4+Pld0PlQuPN4BAHBTSE1Ntf952bJlmjx5sg4ePGhv8/Lysv/ZGKOCggK5uFz6Y7JOnTplqsPV1VW+vr5l2udGkZeXd9UPAK1smNECAFw1Y4x+zbtQIS9jzGXV6Ovra3/5+PjIZrPZ3x84cEDVqlXTJ598orZt28rNzU1bt27V4cOHFRkZqXr16snLy0vt27fXpk2bHI77x1uHNptN8+fPV9++feXp6ammTZtq7dq19u1/vHUYFxen6tWra8OGDWrRooW8vLzUo0cPh2B44cIFjR07VtWrV1etWrU0YcIERUdHq0+fPiVe7+nTpzVw4EAFBATI09NTrVu31pIlSxz6FBYW6tVXX1VwcLDc3NwUFBSkF1980b79559/1sCBA1WzZk1VrVpV7dq1044dOyRJgwcPLnL+xx9/XJ06dbK/79Spk0aPHq3HH39ctWvXVkREhCRp1qxZat26tapWrarAwEA9+uijOnfunMOxtm3bpk6dOsnT01M1atRQRESEfvnlFy1cuFC1atVSbm6uQ/8+ffrooYceKnE8KgozWgCAq3Y+v0AtJ2+okHMnTYuQp2v5fJw988wzmjlzpho3bqwaNWro+PHj6tWrl1588UW5ublp4cKF6t27tw4ePKigoKASj/PCCy/o1Vdf1YwZMzRnzhwNGjRIP/30k2rWrFls/19//VUzZ87UokWL5OTkpAcffFBPPfWUPvjgA0nSK6+8og8++EALFixQixYtFBsbqzVr1qhz584l1pCTk6O2bdtqwoQJ8vb21rp16/TQQw+pSZMmCgsLkyRNnDhR77zzjl577TX95S9/UWpqqg4cOCBJOnfunDp27KiAgACtXbtWvr6+SkhIUGFhYZnG9N///rceeeQRbdu2zd7m5OSk119/XY0aNdKRI0f06KOPavz48XrzzTclSYmJieratauGDh2q2NhYubi46LPPPlNBQYH+/ve/a+zYsVq7dq3+/ve/S5JOnDihdevW6dNPPy1TbdcCQQsAgP81bdo0de/e3f6+Zs2aCgkJsb+fPn26Vq9erbVr12r06NElHmfw4MEaOHCgJOmll17S66+/rp07d6pHjx7F9s/Pz9dbb72lJk2aSJJGjx6tadOm2bfPmTNHEydOVN++fSVJc+fO1ccff1zqtQQEBOipp56yvx8zZow2bNig5cuXKywsTFlZWYqNjdXcuXMVHR0tSWrSpIn+8pe/SJIWL16skydPateuXfaAGBwcXOo5i9O0aVO9+uqrDm2PP/64/c8NGzbU//zP/2jkyJH2oPXqq6+qXbt29veS1KpVK/ufH3jgAS1YsMAetN5//30FBQU5zKZdLwhaAICr5lHFWUnTIirs3OWlXbt2Du/PnTunqVOnat26dUpNTdWFCxd0/vx5HTt2rNTjtGnTxv7nqlWrytvbWydOnCixv6enpz1kSZKfn5+9f0ZGhtLT0+2zUJLk7Oystm3bljq7VFBQoJdeeknLly9XcnKy8vLylJuba3+i//fff6/c3Fx17dq12P0TExN16623ljgLd7natm1bpG3Tpk2KiYnRgQMHlJmZqQsXLignJ0e//vqrPD09lZiYaA9RxRk+fLjat2+v5ORkBQQEKC4uToMHD74uH6JL0AIAXDWbzVZut+8qUtWqVR3eP/XUU9q4caNmzpyp4OBgeXh46N5771VeXl6px/njb+PZbLZSQ1Fx/S937VlJZsyYodjYWM2ePdu+Hurxxx+31+7h4VHq/pfa7uTkVKTGiz/P9Ht/HNP//ve/uvvuu/XII4/oxRdfVM2aNbV161YNGzZMeXl58vT0vOS5b731VoWEhGjhwoW68847tX//fq1bt67UfSoKi+EBACjBtm3bNHjwYPXt21etW7eWr6+v/vvf/17TGnx8fFSvXj3t2rXL3lZQUKCEhIRS99u2bZsiIyP14IMPKiQkRI0bN9ahQ4fs25s2bSoPDw/Fx8cXu3+bNm2UmJioM2fOFLu9Tp06Dgv2pd9mwS5l9+7dKiws1D//+U/dfvvtuuWWW5SSklLk3CXVddHDDz+suLg4LViwQN26dVNgYOAlz10RCFoAAJSgadOmWrVqlRITE7Vnzx498MADZV4MXh7GjBmjmJgYffTRRzp48KAee+wx/fLLL6XeKmvatKk2btyor776St9//73+8Y9/KD093b7d3d1dEyZM0Pjx47Vw4UIdPnxYX3/9td59911J0sCBA+Xr66s+ffpo27ZtOnLkiFauXKnt27dLkrp06aJvvvlGCxcu1A8//KApU6Zo3759l7yW4OBg5efna86cOTpy5IgWLVqkt956y6HPxIkTtWvXLj366KP67rvvdODAAc2bN0+nTp2y93nggQf0888/65133tHQoUPLNJ7XEkELAIASzJo1SzVq1NAdd9yh3r17KyIiQrfddts1r2PChAkaOHCgoqKiFB4eLi8vL0VERMjd3b3EfSZNmqTbbrtNERER6tSpkz00/d7zzz+vJ598UpMnT1aLFi00YMAA+9owV1dXffrpp6pbt6569eql1q1b6+WXX5az829r4iIiIvT8889r/Pjxat++vbKyshQVFXXJawkJCdGsWbP0yiuv6E9/+pM++OADxcTEOPS55ZZb9Omnn2rPnj0KCwtTeHi4PvroI4fnmvn4+Kh///7y8vIq9TEXFc1mrvYmMK5YZmamfHx8lJGRIW9v74ouBwAuS05Ojo4ePapGjRqV+kEP6xQWFqpFixa67777NH369Ioup8J07dpVrVq10uuvv17uxy7t73lZPr8r/8pFAABucD/99JM+/fRTdezYUbm5uZo7d66OHj2qBx54oKJLqxC//PKLtmzZoi1btjg8AuJ6RNACAOA65+TkpLi4OD311FMyxuhPf/qTNm3apBYtWlR0aRXi1ltv1S+//KJXXnlFzZo1q+hySkXQAgDgOhcYGOjwZPWb3bX+5ufVYDE8AACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAlEGnTp30+OOP2983bNhQs2fPLnUfm82mNWvWXPW5y+s4uHYIWgCAm0Lv3r3Vo0ePYrd9+eWXstls+u6778p83F27dmnEiBFXW56DqVOnKjQ0tEh7amqqevbsWa7ngrUIWgCAm8KwYcO0ceNG/fzzz0W2LViwQO3atVObNm3KfNw6derI09OzPEq8JF9fX7m5uV2Tc11P8vLyKrqEK0bQAgDcFO6++27VqVNHcXFxDu3nzp3TihUrNGzYMJ0+fVoDBw5UQECAPD091bp1ay1ZsqTU4/7x1uEPP/ygv/3tb3J3d1fLli21cePGIvtMmDBBt9xyizw9PdW4cWM9//zzys/PlyTFxcXphRde0J49e2Sz2WSz2ew1//HW4d69e9WlSxd5eHioVq1aGjFihM6dO2ffPnjwYPXp00czZ86Un5+fatWqpVGjRtnPVZzDhw8rMjJS9erVk5eXl9q3b69NmzY59MnNzdWECRMUGBgoNzc3BQcH691337Vv379/v+6++255e3urWrVq+utf/6rDhw9LKnrrVZL69OmjwYMHO4zp9OnTFRUVJW9vb/uMYWnjdtF//vMftW/fXu7u7qpdu7b69u0rSZo2bZr+9Kc/Fbne0NBQPf/88yWOx9XiyfAAgKtnjJT/a8Wcu4qnZLNdspuLi4uioqIUFxen5557Trb/3WfFihUqKCjQwIEDde7cObVt21YTJkyQt7e31q1bp4ceekhNmjRRWFjYJc9RWFiofv36qV69etqxY4cyMjKKhApJqlatmuLi4uTv76+9e/dq+PDhqlatmsaPH68BAwZo3759Wr9+vT3g+Pj4FDlGdna2IiIiFB4erl27dunEiRN6+OGHNXr0aIcw+dlnn8nPz0+fffaZfvzxRw0YMEChoaEaPnx4sddw7tw59erVSy+++KLc3Ny0cOFC9e7dWwcPHlRQUJAkKSoqStu3b9frr7+ukJAQHT16VKdOnZIkJScn629/+5s6deqkzZs3y9vbW9u2bdOFCxcuOX6/N3PmTE2ePFlTpky5rHGTpHXr1qlv37567rnntHDhQuXl5enjjz+WJA0dOlQvvPCCdu3apfbt20uSvv32W3333XdatWpVmWorC4IWAODq5f8qveRfMed+NkVyrXpZXYcOHaoZM2bo888/V6dOnST9dtuwf//+8vHxkY+Pj5566il7/zFjxmjDhg1avnz5ZQWtTZs26cCBA9qwYYP8/X8bj5deeqnIuqpJkybZ/9ywYUM99dRTWrp0qcaPHy8PDw95eXnJxcVFvr6+JZ5r8eLFysnJ0cKFC1W16m/XP3fuXPXu3VuvvPKK6tWrJ0mqUaOG5s6dK2dnZzVv3lx33XWX4uPjSwxaISEhCgkJsb+fPn26Vq9erbVr12r06NE6dOiQli9fro0bN6pbt26SpMaNG9v7v/HGG/Lx8dHSpUtVpUoVSdItt9xyybH7oy5duujJJ590aCtt3CTpxRdf1P33368XXnjB4XokqX79+oqIiNCCBQvsQWvBggXq2LGjQ/3ljVuHAICbRvPmzXXHHXfovffekyT9+OOP+vLLLzVs2DBJUkFBgaZPn67WrVurZs2a8vLy0oYNG3Ts2LHLOv7333+vwMBAe8iSpPDw8CL9li1bpj//+c/y9fWVl5eXJk2adNnn+P25QkJC7CFLkv785z+rsLBQBw8etLe1atVKzs7O9vd+fn46ceJEicc9d+6cnnrqKbVo0ULVq1eXl5eXvv/+e3t9iYmJcnZ2VseOHYvdPzExUX/961/tIetKtWvXrkjbpcYtMTFRXbt2LfGYw4cP15IlS5STk6O8vDwtXrxYQ4cOvao6L6XCZ7TeeOMNzZgxQ2lpaQoJCdGcOXNK/K+G/Px8xcTE6N///reSk5PVrFkzvfLKKw7fIpk3b57mzZtn/8HJVq1aafLkyfb/mjhz5oymTJmiTz/9VMeOHVOdOnXUp08fTZ8+3WFq1lbMNPSSJUt0//33299v2bJF48aN0/79+xUYGKhJkyY53GMGgJtGFc/fZpYq6txlMGzYMI0ZM0ZvvPGGFixYoCZNmthDw4wZMxQbG6vZs2erdevWqlq1qh5//PFyXYy9fft2DRo0SC+88IIiIiLssz///Oc/y+0cv/fHwGOz2VRYWFhi/6eeekobN27UzJkzFRwcLA8PD9177732MfDw8Cj1fJfa7uTkJGOMQ1txa8Z+HyClyxu3S527d+/ecnNz0+rVq+Xq6qr8/Hzde++9pe5ztSp0RmvZsmUaN26cpkyZooSEBIWEhCgiIqLEpD1p0iS9/fbbmjNnjpKSkjRy5Ej17dtX3377rb1P/fr19fLLL2v37t365ptv1KVLF0VGRmr//v2SpJSUFKWkpGjmzJnat2+f4uLitH79evt/zfzeggULlJqaan/16dPHvu3o0aO666671LlzZyUmJurxxx/Xww8/rA0bNpTvIAFAZWCz/Xb7riJel7E+6/fuu+8+OTk5afHixVq4cKGGDh1q/4/rbdu2KTIyUg8++KBCQkLUuHFjHTp06LKP3aJFCx0/flypqan2tq+//tqhz1dffaUGDRroueeeU7t27dS0aVP99NNPDn1cXV1VUFBwyXPt2bNH2dnZ9rZt27bJyclJzZo1u+ya/2jbtm0aPHiw+vbtq9atW8vX19c+eSFJrVu3VmFhoT7//PNi92/Tpo2+/PLLEhfc16lTx2F8CgoKtG/fvkvWdTnj1qZNG8XHx5d4DBcXF0VHR2vBggVasGCB7r///kuGs6tmKlBYWJgZNWqU/X1BQYHx9/c3MTExxfb38/Mzc+fOdWjr16+fGTRoUKnnqVGjhpk/f36J25cvX25cXV1Nfn6+vU2SWb16dYn7jB8/3rRq1cqhbcCAASYiIqLEfXJyckxGRob9dfz4cSPJZGRklFo/AFxPzp8/b5KSksz58+crupQrNmzYMFOjRg3j7OxskpOT7e1PPPGECQwMNNu2bTNJSUnm4YcfNt7e3iYyMtLep2PHjuaxxx6zv2/QoIF57bXXjDG/fY61bNnSdO/e3SQmJpovvvjCtG3b1uEz5aOPPjIuLi5myZIl5scffzSxsbGmZs2axsfHx37MDz74wFStWtV8++235uTJkyYnJ8cY4/jZlJ2dbfz8/Ez//v3N3r17zebNm03jxo1NdHS0/TjR0dEOtRtjzGOPPWY6duxY4tj07dvXhIaGmm+//dYkJiaa3r17m2rVqjlc8+DBg01gYKBZvXq1OXLkiPnss8/MsmXLjDHGnDp1ytSqVcv069fP7Nq1yxw6dMgsXLjQHDhwwBhjzFtvvWU8PT3N//t//898//33Zvjw4cbb29uh7t+P6UWXM26fffaZcXJyMpMnTzZJSUnmu+++My+//LLDcQ4dOmScnZ2Ns7Oz+frrr0sch9L+nmdkZFz253eFzWjl5eVp9+7d9oV00m/Tid26ddP27duL3Sc3N1fu7u4ObR4eHtq6dWux/QsKCrR06VJlZ2cXe4/8ooyMDHl7e8vFxfFO6qhRo1S7dm2FhYXpvffec5jq3L59u0PtkhQREVFi7ZIUExNjX2zp4+OjwMDAEvsCAKwzbNgw/fLLL4qIiHBYTzVp0iTddtttioiIUKdOneTr6+twN+NSnJyctHr1ap0/f15hYWF6+OGH9eKLLzr0ueeee/TEE09o9OjRCg0N1VdffVXk8QL9+/dXjx491LlzZ9WpU6fYR0x4enpqw4YNOnPmjNq3b697771XXbt21dy5c8s2GH8wa9Ys1ahRQ3fccYd69+6tiIgI3XbbbQ595s2bp3vvvVePPvqomjdvruHDh9tn1mrVqqXNmzfr3Llz6tixo9q2bat33nnHfgtz6NChio6OVlRUlH0heufOnS9Z1+WMW6dOnbRixQqtXbtWoaGh6tKli3bu3OnQp2nTprrjjjvUvHlzdejQ4WqG6vJcMopZJDk52UgyX331lUP7008/bcLCwordZ+DAgaZly5bm0KFDpqCgwHz66afGw8PDuLq6OvT77rvvTNWqVY2zs7Px8fEx69atK7GOkydPmqCgIPPss886tE+bNs1s3brVJCQkmJdfftm4ubmZ2NhY+/amTZual156yWGfdevWGUnm119/LfZczGgBuBHcCDNauHkVFhaaJk2amH/+85+l9iuvGa0KXwxfFrGxsRo+fLiaN28um82mJk2aaMiQIfZvj1zUrFkzJSYmKiMjQx9++KGio6P1+eefq2XLlg79MjMzddddd6lly5aaOnWqw7bfp+Rbb71V2dnZmjFjhsaOHXvF9bu5ud2UT/QFAOB6cPLkSS1dulRpaWkaMmTINTlnhd06rF27tpydnZWenu7Qnp6eXuJzQ+rUqaM1a9YoOztbP/30kw4cOCAvL68iz79wdXVVcHCw2rZtq5iYGIWEhCg2NtahT1ZWlnr06KFq1app9erVl/waaocOHfTzzz8rNzdX0m8/g1Bc7d7e3tYvrAMAAGVWt25dTZs2Tf/6179Uo0aNa3LOCgtarq6uatu2rcO3AwoLCxUfH1/qeipJcnd3V0BAgC5cuKCVK1cqMjKy1P6FhYX2gCT9NpN15513ytXVVWvXri2y7qs4iYmJqlGjhn1GKjw8vMg3GzZu3HjJ2gEAQMUwxujkyZN64IEHrtk5K/TW4bhx4xQdHa127dopLCxMs2fPVnZ2tn06LyoqSgEBAYqJiZEk7dixQ8nJyQoNDVVycrKmTp2qwsJC+xNhJWnixInq2bOngoKClJWVpcWLF2vLli32xy5cDFm//vqr3n//fWVmZiozM1PSbzNmzs7O+s9//qP09HTdfvvtcnd318aNG/XSSy85PC145MiRmjt3rsaPH6+hQ4dq8+bNWr58udatW3ethg8AAFznKjRoDRgwQCdPntTkyZOVlpam0NBQrV+/3v6zAceOHZOT0/9NuuXk5GjSpEk6cuSIvLy81KtXLy1atEjVq1e39zlx4oSioqKUmpoqHx8ftWnTRhs2bFD37t0lSQkJCdqxY4ckKTg42KGeo0ePqmHDhqpSpYreeOMNPfHEEzLGKDg4WLNmzXL4uYJGjRpp3bp1euKJJxQbG6v69etr/vz5ioiIsGq4AOC6Yv7w0EngRlJef79thn9SKkxmZqZ8fHzsj5cAgMqgoKBAhw4dUt26dVWrVq2KLgewREZGhlJSUhQcHFxkHXdZPr8r1bcOAQAVz9nZWdWrV7f/ioenp2exP1sGVFaFhYU6efKkPD09izxjs6wIWgCAMrv47fDSfpwYqMycnJwUFBR01f8RQdACAJSZzWaTn5+f6tatW+Jv2gGVmaurq8M68StF0AIAXDFnZ2c5OztXdBnAdavCnqMFAABwoyNoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgkQoPWm+88YYaNmwod3d3dejQQTt37iyxb35+vqZNm6YmTZrI3d1dISEhWr9+vUOfefPmqU2bNvL29pa3t7fCw8P1ySef2LefOXNGY8aMUbNmzeTh4aGgoCCNHTtWGRkZxZ7z9OnTql+/vmw2m86ePWtv37Jli2w2W5FXWlra1Q0IAAC4YVRo0Fq2bJnGjRunKVOmKCEhQSEhIYqIiNCJEyeK7T9p0iS9/fbbmjNnjpKSkjRy5Ej17dtX3377rb1P/fr19fLLL2v37t365ptv1KVLF0VGRmr//v2SpJSUFKWkpGjmzJnat2+f4uLitH79eg0bNqzYcw4bNkxt2rQp8RoOHjyo1NRU+6tu3bpXMSIAAOCGYipQWFiYGTVqlP19QUGB8ff3NzExMcX29/PzM3PnznVo69evnxk0aFCp56lRo4aZP39+iduXL19uXF1dTX5+vkP7m2++aTp27Gji4+ONJPPLL7/Yt3322WdF2i4lJyfHZGRk2F/Hjx83kkxGRsZlHwMAAFSsjIyMy/78rrAZrby8PO3evVvdunWztzk5Oalbt27avn17sfvk5ubK3d3doc3Dw0Nbt24ttn9BQYGWLl2q7OxshYeHl1hLRkaGvL295eLiYm9LSkrStGnTtHDhQjk5lTxMoaGh8vPzU/fu3bVt27YS+0lSTEyMfHx87K/AwMBS+wMAgMqtwoLWqVOnVFBQoHr16jm016tXr8R1ThEREZo1a5Z++OEHFRYWauPGjVq1apVSU1Md+u3du1deXl5yc3PTyJEjtXr1arVs2bLEOqZPn64RI0bY23JzczVw4EDNmDFDQUFBxe7n5+ent956SytXrtTKlSsVGBioTp06KSEhocRrnjhxojIyMuyv48ePl9gXAABUfi6X7nL9iI2N1fDhw9W8eXPZbDY1adJEQ4YM0XvvvefQr1mzZkpMTFRGRoY+/PBDRUdH6/PPPy8StjIzM3XXXXepZcuWmjp1qr194sSJatGihR588MESa2nWrJmaNWtmf3/HHXfo8OHDeu2117Ro0aJi93Fzc5Obm9sVXDkAAKiMKmxGq3bt2nJ2dlZ6erpDe3p6unx9fYvdp06dOlqzZo2ys7P1008/6cCBA/Ly8lLjxo0d+rm6uio4OFht27ZVTEyMQkJCFBsb69AnKytLPXr0ULVq1bR69WpVqVLFvm3z5s1asWKFXFxc5OLioq5du9prnjJlSonXFBYWph9//LFM4wAAAG5cFTaj5erqqrZt2yo+Pl59+vSRJBUWFio+Pl6jR48udV93d3cFBAQoPz9fK1eu1H333Vdq/8LCQuXm5trfZ2ZmKiIiQm5ublq7dm2RdV8rV67U+fPn7e937dqloUOH6ssvv1STJk1KPE9iYqL8/PxKrQUAANw8KvTW4bhx4xQdHa127dopLCxMs2fPVnZ2toYMGSJJioqKUkBAgGJiYiRJO3bsUHJyskJDQ5WcnKypU6eqsLBQ48ePtx9z4sSJ6tmzp4KCgpSVlaXFixdry5Yt2rBhg6TfQtadd96pX3/9Ve+//74yMzOVmZkp6bcZM2dn5yJh6tSpU5KkFi1aqHr16pKk2bNnq1GjRmrVqpVycnI0f/58bd68WZ9++qmlYwYAACqPCg1aAwYM0MmTJzV58mSlpaUpNDRU69evty+QP3bsmMM3/nJycjRp0iQdOXJEXl5e6tWrlxYtWmQPP5J04sQJRUVFKTU1VT4+PmrTpo02bNig7t27S5ISEhK0Y8cOSVJwcLBDPUePHlXDhg0vq/a8vDw9+eSTSk5Olqenp9q0aaNNmzapc+fOVzEiAADgRmIzxpiKLuJmlZmZKR8fH/vjJQAAwPWvLJ/fFf4TPAAAADcqghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFilz0GrYsKGmTZumY8eOWVEPAADADaPMQevxxx/XqlWr1LhxY3Xv3l1Lly5Vbm6uFbUBAABUalcUtBITE7Vz5061aNFCY8aMkZ+fn0aPHq2EhAQragQAAKiUbMYYczUHyM/P15tvvqkJEyYoPz9frVu31tixYzVkyBDZbLbyqvOGlJmZKR8fH2VkZMjb27uiywEAAJehLJ/fLld6kvz8fK1evVoLFizQxo0bdfvtt2vYsGH6+eef9eyzz2rTpk1avHjxlR4eAACg0itz0EpISNCCBQu0ZMkSOTk5KSoqSq+99pqaN29u79O3b1+1b9++XAsFAACobMoctNq3b6/u3btr3rx56tOnj6pUqVKkT6NGjXT//feXS4EAAACVVZmD1pEjR9SgQYNS+1StWlULFiy44qIAAABuBGX+1uGJEye0Y8eOIu07duzQN998Uy5FAQAA3AjKHLRGjRql48ePF2lPTk7WqFGjyqUoAACAG0GZg1ZSUpJuu+22Iu233nqrkpKSyqUoAACAG0GZg5abm5vS09OLtKempsrF5YqfFgEAAHDDKXPQuvPOOzVx4kRlZGTY286ePatnn31W3bt3L9fiAAAAKrMyT0HNnDlTf/vb39SgQQPdeuutkqTExETVq1dPixYtKvcCAQAAKqsyB62AgAB99913+uCDD7Rnzx55eHhoyJAhGjhwYLHP1AIAALhZXdGiqqpVq2rEiBHlXQsAAMAN5YpXryclJenYsWPKy8tzaL/nnnuuuigAAIAbwRU9Gb5v377au3evbDabjDGSJJvNJkkqKCgo3woBAAAqqTJ/6/Cxxx5To0aNdOLECXl6emr//v364osv1K5dO23ZssWCEgEAACqnMs9obd++XZs3b1bt2rXl5OQkJycn/eUvf1FMTIzGjh2rb7/91oo6AQAAKp0yz2gVFBSoWrVqkqTatWsrJSVFktSgQQMdPHiwfKsDAACoxMo8o/WnP/1Je/bsUaNGjdShQwe9+uqrcnV11b/+9S81btzYihoBAAAqpTIHrUmTJik7O1uSNG3aNN19993661//qlq1amnZsmXlXiAAAEBlZTMXvzZ4Fc6cOaMaNWrYv3mIy5OZmSkfHx9lZGTI29u7ossBAACXoSyf32Vao5Wfny8XFxft27fPob1mzZqELAAAgD8oU9CqUqWKgoKCeFYWAADAZSjztw6fe+45Pfvsszpz5owV9QAAANwwyrwYfu7cufrxxx/l7++vBg0aqGrVqg7bExISyq04AACAyqzMQatPnz4WlAEAAHDjKZdvHeLK8K1DAAAqH8u+dQgAAIDLV+Zbh05OTqU+yoFvJAIAAPymzDNaq1ev1qpVq+yvZcuW6ZlnnpGfn5/+9a9/lbmAN954Qw0bNpS7u7s6dOignTt3ltg3Pz9f06ZNU5MmTeTu7q6QkBCtX7/eoc+8efPUpk0beXt7y9vbW+Hh4frkk0/s28+cOaMxY8aoWbNm8vDwUFBQkMaOHauMjIxiz3n69GnVr19fNptNZ8+eddi2ZcsW3XbbbXJzc1NwcLDi4uLKfP0AAOAGZsrJBx98YO65554y7bN06VLj6upq3nvvPbN//34zfPhwU716dZOenl5s//Hjxxt/f3+zbt06c/jwYfPmm28ad3d3k5CQYO+zdu1as27dOnPo0CFz8OBB8+yzz5oqVaqYffv2GWOM2bt3r+nXr59Zu3at+fHHH018fLxp2rSp6d+/f7HnjIyMND179jSSzC+//GJvP3LkiPH09DTjxo0zSUlJZs6cOcbZ2dmsX7/+sq8/IyPDSDIZGRmXvQ8AAKhYZfn8LregdfjwYVO1atUy7RMWFmZGjRplf19QUGD8/f1NTExMsf39/PzM3LlzHdr69etnBg0aVOp5atSoYebPn1/i9uXLlxtXV1eTn5/v0P7mm2+ajh07mvj4+CJBa/z48aZVq1YO/QcMGGAiIiJKPE9OTo7JyMiwv44fP07QAgCgkilL0CqXxfDnz5/X66+/roCAgMveJy8vT7t371a3bt3sbU5OTurWrZu2b99e7D65ublyd3d3aPPw8NDWrVuL7V9QUKClS5cqOztb4eHhJdZy8VsDLi7/t2QtKSlJ06ZN08KFC+XkVHSYtm/f7lC7JEVERJRYuyTFxMTIx8fH/goMDCyxLwAAqPzKvBj+jz8ebYxRVlaWPD099f7771/2cU6dOqWCggLVq1fPob1evXo6cOBAsftERERo1qxZ+tvf/qYmTZooPj5eq1atKrIAf+/evQoPD1dOTo68vLy0evVqtWzZssQ6pk+frhEjRtjbcnNzNXDgQM2YMUNBQUE6cuRIkf3S0tKKrT0zM1Pnz5+Xh4dHkX0mTpyocePG2d9nZmYStgAAuIGVOWi99tprDkHLyclJderUUYcOHVSjRo1yLe6PYmNjNXz4cDVv3lw2m01NmjTRkCFD9N577zn0a9asmRITE5WRkaEPP/xQ0dHR+vzzz4uErczMTN11111q2bKlpk6dam+fOHGiWrRooQcffLBc63dzc5Obm1u5HhMAAFy/yhy0Bg8eXC4nrl27tpydnZWenu7Qnp6eLl9f32L3qVOnjtasWaOcnBydPn1a/v7+euaZZ9S4cWOHfq6urgoODpYktW3bVrt27VJsbKzefvtte5+srCz16NFD1apV0+rVq1WlShX7ts2bN2vv3r368MMPJf02a3ex5ueee04vvPCCfH19i63d29u72NksAABw8ynzGq0FCxZoxYoVRdpXrFihf//735d9HFdXV7Vt21bx8fH2tsLCQsXHx5e6nkqS3N3dFRAQoAsXLmjlypWKjIwstX9hYaFyc3Pt7zMzM3XnnXfK1dVVa9euLbLua+XKldqzZ48SExOVmJio+fPnS5K+/PJLjRo1SpIUHh7uULskbdy48ZK1AwCAm0eZZ7RiYmIcZoYuqlu3rkaMGKHo6OjLPta4ceMUHR2tdu3aKSwsTLNnz1Z2draGDBkiSYqKilJAQIBiYmIkSTt27FBycrJCQ0OVnJysqVOnqrCwUOPHj7cfc+LEierZs6eCgoKUlZWlxYsXa8uWLdqwYYOk/wtZv/76q95//31lZmYqMzNT0m8zZs7OzmrSpIlDnadOnZIktWjRQtWrV5ckjRw5UnPnztX48eM1dOhQbd68WcuXL9e6desu+/oBAMCNrcxB69ixY2rUqFGR9gYNGujYsWNlOtaAAQN08uRJTZ48WWlpaQoNDdX69evti8yPHTvm8I2/nJwcTZo0SUeOHJGXl5d69eqlRYsW2cOPJJ04cUJRUVFKTU2Vj4+P2rRpow0bNqh79+6SpISEBO3YsUOS7LcXLzp69KgaNmx4WbU3atRI69at0xNPPKHY2FjVr19f8+fPV0RERJnGAAAA3LjK/KPSQUFBmjt3ru655x6H9o8++kijRo3Szz//XK4F3sj4UWkAACofS39UeuDAgRo7dqw+++wzFRQUqKCgQJs3b9Zjjz2m+++//4qLBgAAuNGU+dbh9OnT9d///lddu3a1P+CzsLBQUVFReumll8q9QAAAgMqqzLcOL/rhhx+UmJgoDw8PtW7dWg0aNCjv2m543DoEAKDyKcvnd5lntC5q2rSpmjZteqW7AwAA3PDKvEarf//+euWVV4q0v/rqq/r73/9eLkUBAADcCMoctL744gv16tWrSHvPnj31xRdflEtRAAAAN4IyB61z587J1dW1SHuVKlXsD/4EAADAFQSt1q1ba9myZUXaly5dWuRHmwEAAG5mZV4M//zzz6tfv346fPiwunTpIkmKj4/X4sWL7T/CDAAAgCsIWr1799aaNWv00ksv6cMPP5SHh4dCQkK0efNm1axZ04oaAQAAKqUrfo7WRZmZmVqyZIneffdd7d69WwUFBeVV2w2P52gBAFD5WPoTPBd98cUXio6Olr+/v/75z3+qS5cu+vrrr6/0cAAAADecMt06TEtLU1xcnN59911lZmbqvvvuU25urtasWcNCeAAAgD+47Bmt3r17q1mzZvruu+80e/ZspaSkaM6cOVbWBgAAUKld9ozWJ598orFjx+qRRx7hp3cAAAAuw2XPaG3dulVZWVlq27atOnTooLlz5+rUqVNW1gYAAFCpXXbQuv322/XOO+8oNTVV//jHP7R06VL5+/ursLBQGzduVFZWlpV1AgAAVDpX9XiHgwcP6t1339WiRYt09uxZde/eXWvXri3P+m5oPN4BAIDK55o83kGSmjVrpldffVU///yzlixZcjWHAgAAuOFc9QNLceWY0QIAoPK5ZjNaAAAAKBlBCwAAwCIELQAAAIsQtAAAACxC0AIAALAIQQsAAMAiBC0AAACLELQAAAAsQtACAACwCEELAADAIgQtAAAAixC0AAAALELQAgAAsAhBCwAAwCIELQAAAIsQtAAAACxC0AIAALAIQQsAAMAiBC0AAACLELQAAAAsQtACAACwCEELAADAIgQtAAAAixC0AAAALELQAgAAsAhBCwAAwCIELQAAAIsQtAAAACxC0AIAALAIQQsAAMAiBC0AAACLELQAAAAsQtACAACwCEELAADAIgQtAAAAixC0AAAALELQAgAAsAhBCwAAwCIELQAAAIsQtAAAACxC0AIAALAIQQsAAMAiBC0AAACLVHjQeuONN9SwYUO5u7urQ4cO2rlzZ4l98/PzNW3aNDVp0kTu7u4KCQnR+vXrHfrMmzdPbdq0kbe3t7y9vRUeHq5PPvnEvv3MmTMaM2aMmjVrJg8PDwUFBWns2LHKyMiw9zl9+rR69Oghf39/ubm5KTAwUKNHj1ZmZqa9z5YtW2Sz2Yq80tLSynF0AABAZVahQWvZsmUaN26cpkyZooSEBIWEhCgiIkInTpwotv+kSZP09ttva86cOUpKStLIkSPVt29fffvtt/Y+9evX18svv6zdu3frm2++UZcuXRQZGan9+/dLklJSUpSSkqKZM2dq3759iouL0/r16zVs2DD7MZycnBQZGam1a9fq0KFDiouL06ZNmzRy5MgiNR08eFCpqan2V926dct5lAAAQGVlM8aYijp5hw4d1L59e82dO1eSVFhYqMDAQI0ZM0bPPPNMkf7+/v567rnnNGrUKHtb//795eHhoffff7/E89SsWVMzZsxwCFO/t2LFCj344IPKzs6Wi4tLsX1ef/11zZgxQ8ePH5f024xW586d9csvv6h69eqXdb25ubnKzc21v8/MzFRgYKAyMjLk7e19WccAAAAVKzMzUz4+Ppf1+V1hM1p5eXnavXu3unXr9n/FODmpW7du2r59e7H75Obmyt3d3aHNw8NDW7duLbZ/QUGBli5dquzsbIWHh5dYy8WBKilkpaSkaNWqVerYsWORbaGhofLz81P37t21bdu2Es8hSTExMfLx8bG/AgMDS+0PAAAqtwoLWqdOnVJBQYHq1avn0F6vXr0S1zlFRERo1qxZ+uGHH1RYWKiNGzdq1apVSk1Ndei3d+9eeXl5yc3NTSNHjtTq1avVsmXLEuuYPn26RowYUWTbwIED5enpqYCAAHl7e2v+/Pn2bX5+fnrrrbe0cuVKrVy5UoGBgerUqZMSEhJKvOaJEycqIyPD/ro4OwYAAG5MFXbrMCUlRQEBAfrqq68cZpvGjx+vzz//XDt27Ciyz8mTJzV8+HD95z//kc1mU5MmTdStWze99957On/+vL1fXl6ejh07poyMDH344YeaP3++Pv/88yJhKzMzU927d1fNmjW1du1aValSxWF7Wlqazp49q0OHDmnixInq2LGj3nzzzRKvqWPHjgoKCtKiRYsuawzKMvUIAACuD5Xi1mHt2rXl7Oys9PR0h/b09HT5+voWu0+dOnW0Zs0aZWdn66efftKBAwfk5eWlxo0bO/RzdXVVcHCw2rZtq5iYGIWEhCg2NtahT1ZWlnr06KFq1app9erVRUKWJPn6+qp58+a655579Pbbb2vevHlFZs9+LywsTD/++OPlDgEAALjBVVjQcnV1Vdu2bRUfH29vKywsVHx8fKnrqSTJ3d1dAQEBunDhglauXKnIyMhS+xcWFhZZhH7nnXfK1dVVa9euLbLuq6RjSHI4zh8lJibKz8/vkscCAAA3h+JXf18j48aNU3R0tNq1a6ewsDDNnj1b2dnZGjJkiCQpKipKAQEBiomJkSTt2LFDycnJCg0NVXJysqZOnarCwkKNHz/efsyJEyeqZ8+eCgoKUlZWlhYvXqwtW7Zow4YNkv4vZP366696//33lZmZaX8+Vp06deTs7KyPP/5Y6enpat++vby8vLR//349/fTT+vOf/6yGDRtKkmbPnq1GjRqpVatWysnJ0fz587V582Z9+umn13AEAQDA9axCg9aAAQN08uRJTZ48WWlpaQoNDdX69evtC+SPHTsmJ6f/m3TLycnRpEmTdOTIEXl5ealXr15atGiRw+MVTpw4oaioKKWmpsrHx0dt2rTRhg0b1L17d0lSQkKCff1XcHCwQz1Hjx5Vw4YN5eHhoXfeeUdPPPGEcnNzFRgYqH79+jk8ciIvL09PPvmkkpOT5enpqTZt2mjTpk3q3LmzVcMFAAAqmQp9jtbNjsXwAABUPpViMTwAAMCNjqAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARSo8aL3xxhtq2LCh3N3d1aFDB+3cubPEvvn5+Zo2bZqaNGkid3d3hYSEaP369Q595s2bpzZt2sjb21ve3t4KDw/XJ598Yt9+5swZjRkzRs2aNZOHh4eCgoI0duxYZWRk2PucPn1aPXr0kL+/v9zc3BQYGKjRo0crMzPT4VxbtmzRbbfdJjc3NwUHBysuLq58BgUAANwQKjRoLVu2TOPGjdOUKVOUkJCgkJAQRURE6MSJE8X2nzRpkt5++23NmTNHSUlJGjlypPr27atvv/3W3qd+/fp6+eWXtXv3bn3zzTfq0qWLIiMjtX//fklSSkqKUlJSNHPmTO3bt09xcXFav369hg0bZj+Gk5OTIiMjtXbtWh06dEhxcXHatGmTRo4cae9z9OhR3XXXXercubMSExP1+OOP6+GHH9aGDRssGi0AAFDpmAoUFhZmRo0aZX9fUFBg/P39TUxMTLH9/fz8zNy5cx3a+vXrZwYNGlTqeWrUqGHmz59f4vbly5cbV1dXk5+fX2Kf2NhYU79+ffv78ePHm1atWjn0GTBggImIiCi1lt/LyMgwkkxGRsZl7wMAACpWWT6/K2xGKy8vT7t371a3bt3sbU5OTurWrZu2b99e7D65ublyd3d3aPPw8NDWrVuL7V9QUKClS5cqOztb4eHhJdaSkZEhb29vubi4FLs9JSVFq1atUseOHe1t27dvd6hdkiIiIkqs/WL9mZmZDi8AAHDjqrCgderUKRUUFKhevXoO7fXq1VNaWlqx+0RERGjWrFn64YcfVFhYqI0bN2rVqlVKTU116Ld37155eXnJzc1NI0eO1OrVq9WyZcsS65g+fbpGjBhRZNvAgQPl6empgIAAeXt7a/78+fZtaWlpxdaemZmp8+fPF3uumJgY+fj42F+BgYHF9gMAADeGCl8MXxaxsbFq2rSpmjdvLldXV40ePVpDhgyRk5PjZTRr1kyJiYnasWOHHnnkEUVHRyspKanI8TIzM3XXXXepZcuWmjp1apHtr732mhISEvTRRx/p8OHDGjdu3FXVP3HiRGVkZNhfx48fv6rjAQCA61vx98qugdq1a8vZ2Vnp6ekO7enp6fL19S12nzp16mjNmjXKycnR6dOn5e/vr2eeeUaNGzd26Ofq6qrg4GBJUtu2bbVr1y7Fxsbq7bfftvfJyspSjx49VK1aNa1evVpVqlQpcj5fX1/5+vqqefPmqlmzpv7617/q+eefl5+fn3x9fYut3dvbWx4eHsXW7+bmJjc3t0sPDgAAuCFU2IyWq6ur2rZtq/j4eHtbYWGh4uPjS11PJUnu7u4KCAjQhQsXtHLlSkVGRpbav7CwULm5ufb3mZmZuvPOO+Xq6qq1a9cWWfdV0jEk2Y8THh7uULskbdy48ZK1AwCAm0eFzWhJ0rhx4xQdHa127dopLCxMs2fPVnZ2toYMGSJJioqKUkBAgGJiYiRJO3bsUHJyskJDQ5WcnKypU6eqsLBQ48ePtx9z4sSJ6tmzp4KCgpSVlaXFixdry5Yt9scuXAxZv/76q95//32HRel16tSRs7OzPv74Y6Wnp6t9+/by8vLS/v379fTTT+vPf/6zGjZsKEkaOXKk5s6dq/Hjx2vo0KHavHmzli9frnXr1l3DEQQAANezCg1aAwYM0MmTJzV58mSlpaUpNDRU69evty8yP3bsmMP6q5ycHE2aNElHjhyRl5eXevXqpUWLFql69er2PidOnFBUVJRSU1Pl4+OjNm3aaMOGDerevbskKSEhQTt27JAk++3Fi44ePaqGDRvKw8ND77zzjp544gnl5uYqMDBQ/fr10zPPPGPv26hRI61bt05PPPGEYmNjVb9+fc2fP18RERFWDRcAAKhkbMYYU9FF3KwyMzPl4+Njf7wEAAC4/pXl87tSfesQAACgMiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABYhKAFAABgEYIWAACARQhaAAAAFiFoAQAAWISgBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWcanoAm5mxhhJUmZmZgVXAgAALtfFz+2Ln+OlIWhVoKysLElSYGBgBVcCAADKKisrSz4+PqX2sZnLiWOwRGFhoVJSUlStWjXZbLaKLqfCZWZmKjAwUMePH5e3t3dFl3PDYpyvDcb52mCcrx3G+v8YY5SVlSV/f385OZW+CosZrQrk5OSk+vXrV3QZ1x1vb++b/h/ia4FxvjYY52uDcb52GOvfXGom6yIWwwMAAFiEoAUAAGARghauG25ubpoyZYrc3NwqupQbGuN8bTDO1wbjfO0w1leGxfAAAAAWYUYLAADAIgQtAAAAixC0AAAALELQAgAAsAhBC9fMmTNnNGjQIHl7e6t69eoaNmyYzp07V+o+OTk5GjVqlGrVqiUvLy/1799f6enpxfY9ffq06tevL5vNprNnz1pwBZWDFeO8Z88eDRw4UIGBgfLw8FCLFi0UGxtr9aVcd9544w01bNhQ7u7u6tChg3bu3Flq/xUrVqh58+Zyd3dX69at9fHHHztsN8Zo8uTJ8vPzk4eHh7p166YffvjBykuoFMpznPPz8zVhwgS1bt1aVatWlb+/v6KiopSSkmL1ZVz3yvvv8++NHDlSNptNs2fPLueqKyEDXCM9evQwISEh5uuvvzZffvmlCQ4ONgMHDix1n5EjR5rAwEATHx9vvvnmG3P77bebO+64o9i+kZGRpmfPnkaS+eWXXyy4gsrBinF+9913zdixY82WLVvM4cOHzaJFi4yHh4eZM2eO1Zdz3Vi6dKlxdXU17733ntm/f78ZPny4qV69uklPTy+2/7Zt24yzs7N59dVXTVJSkpk0aZKpUqWK2bt3r73Pyy+/bHx8fMyaNWvMnj17zD333GMaNWpkzp8/f60u67pT3uN89uxZ061bN7Ns2TJz4MABs337dhMWFmbatm17LS/rumPF3+eLVq1aZUJCQoy/v7957bXXLL6S6x9BC9dEUlKSkWR27dplb/vkk0+MzWYzycnJxe5z9uxZU6VKFbNixQp72/fff28kme3btzv0ffPNN03Hjh1NfHz8TR20rB7n33v00UdN586dy6/461xYWJgZNWqU/X1BQYHx9/c3MTExxfa/7777zF133eXQ1qFDB/OPf/zDGGNMYWGh8fX1NTNmzLBvP3v2rHFzczNLliyx4Aoqh/Ie5+Ls3LnTSDI//fRT+RRdCVk1zj///LMJCAgw+/btMw0aNCBoGWO4dYhrYvv27apevbratWtnb+vWrZucnJy0Y8eOYvfZvXu38vPz1a1bN3tb8+bNFRQUpO3bt9vbkpKSNG3aNC1cuPCSP+55o7NynP8oIyNDNWvWLL/ir2N5eXnavXu3wxg5OTmpW7duJY7R9u3bHfpLUkREhL3/0aNHlZaW5tDHx8dHHTp0KHXcb2RWjHNxMjIyZLPZVL169XKpu7KxapwLCwv10EMP6emnn1arVq2sKb4Surk/lXDNpKWlqW7dug5tLi4uqlmzptLS0krcx9XVtci/DOvVq2ffJzc3VwMHDtSMGTMUFBRkSe2ViVXj/EdfffWVli1bphEjRpRL3de7U6dOqaCgQPXq1XNoL22M0tLSSu1/8X/LcswbnRXj/Ec5OTmaMGGCBg4ceNP+MLJV4/zKK6/IxcVFY8eOLf+iKzGCFq7KM888I5vNVurrwIEDlp1/4sSJatGihR588EHLznE9qOhx/r19+/YpMjJSU6ZM0Z133nlNzgmUh/z8fN13330yxmjevHkVXc4NZffu3YqNjVVcXJxsNltFl3NdcanoAlC5Pfnkkxo8eHCpfRo3bixfX1+dOHHCof3ChQs6c+aMfH19i93P19dXeXl5Onv2rMNsS3p6un2fzZs3a+/evfrwww8l/fYtLkmqXbu2nnvuOb3wwgtXeGXXl4oe54uSkpLUtWtXjRgxQpMmTbqia6mMateuLWdn5yLfeC1ujC7y9fUttf/F/01PT5efn59Dn9DQ0HKsvvKwYpwvuhiyfvrpJ23evPmmnc2SrBnnL7/8UidOnHC4s1BQUKAnn3xSs2fP1n//+9/yvYjKpKIXieHmcHGR9jfffGNv27Bhw2Ut0v7www/tbQcOHHBYpP3jjz+avXv32l/vvfeekWS++uqrEr89cyOzapyNMWbfvn2mbt265umnn7buAq5jYWFhZvTo0fb3BQUFJiAgoNTFw3fffbdDW3h4eJHF8DNnzrRvz8jIYDF8OY+zMcbk5eWZPn36mFatWpkTJ05YU3glU97jfOrUKYd/F+/du9f4+/ubCRMmmAMHDlh3IZUAQQvXTI8ePcytt95qduzYYbZu3WqaNm3q8NiBn3/+2TRr1szs2LHD3jZy5EgTFBRkNm/ebL755hsTHh5uwsPDSzzHZ599dlN/69AYa8Z57969pk6dOubBBx80qamp9tfN9KG1dOlS4+bmZuLi4kxSUpIZMWKEqV69uklLSzPGGPPQQw+ZZ555xt5/27ZtxsXFxcycOdN8//33ZsqUKcU+3qF69ermo48+Mt99952JjIzk8Q7lPM55eXnmnnvuMfXr1zeJiYkOf39zc3Mr5BqvB1b8ff4jvnX4G4IWrpnTp0+bgQMHGi8vL+Pt7W2GDBlisrKy7NuPHj1qJJnPPvvM3nb+/Hnz6KOPmho1ahhPT0/Tt29fk5qaWuI5CFrWjPOUKVOMpCKvBg0aXMMrq3hz5swxQUFBxtXV1YSFhZmvv/7avq1jx44mOjraof/y5cvNLbfcYlxdXU2rVq3MunXrHLYXFhaa559/3tSrV8+4ubmZrl27moMHD16LS7mulec4X/z7Xtzr9/8M3IzK++/zHxG0fmMz5n8XtQAAAKBc8a1DAAAAixC0AAAALELQAgAAsAhBCwAAwCIELQAAAIsQtAAAACxC0AIAALAIQQsAAMAiBC0AuI7YbDatWbOmossAUE4IWgDwvwYPHiybzVbk1aNHj4ouDUAl5VLRBQDA9aRHjx5asGCBQ5ubm1sFVQOgsmNGCwB+x83NTb6+vg6vGjVqSPrttt68efPUs2dPeXh4qHHjxvrwww8d9t+7d6+6dOkiDw8P1apVSyNGjNC5c+cc+rz33ntq1aqV3Nzc5Ofnp9GjRztsP3XqlPr27StPT081bdpUa9eutfaiAViGoAUAZfD888+rf//+2rNnjwYNGqT7779f33//vSQpOztbERERqlGjhnbt2qUVK1Zo06ZNDkFq3rx5GjVqlEaMGKG9e/dq7dq1Cg4OdjjHCy+8oPvuu0/fffedevXqpUGDBunMmTPX9DoBlBMDADDGGBMdHW2cnZ1N1apVHV4vvviiMcYYSWbkyJEO+3To0ME88sgjxhhj/vWvf5kaNWqYc+fO2bevW7fOODk5mbS0NGOMMf7+/ua5554rsQZJZtKkSfb3586dM5LMJ598Um7XCeDaYY0WAPxO586dNW/ePIe2mjVr2v8cHh7usC08PFyJiYmSpO+//14hISGqWrWqffuf//xnFRYW6uDBg7LZbEpJSVHXrl1LraFNmzb2P1etWlXe3t46ceLElV4SgApE0AKA36latWqRW3nlxcPD47L6ValSxeG9zWZTYWGhFSUBsBhrtACgDL7++usi71u0aCFJatGihfbs2aPs7Gz79m3btsnJyUnNmjVTtWrV1LBhQ8XHx1/TmgFUHGa0AOB3cnNzlZaW5tDm4uKi2rVrS5JWrFihdu3a6S9/+Ys++OAD7dy5U++++64kadCgQZoyZYqio6M1depUnTx5UmPGjNFDDz2kevXqSZKmTp2qkSNHqm7duurZs6eysrK0bds2jRkz5tpeKIBrgqAFAL+zfv16+fn5ObQ1a9ZMBw4ckPTbNwKXLl2qRx99VH5+flqyZIlatmwpSfL09NSGDRv02GOPqX379vL09FT//v01a9Ys+7Gio6OVk5Oj1157TU899ZRq166te++999pdIIBrymaMMRVdBABUBjabTatXr1afPn0quhQAlQRrtAAAACxC0AIAALAIa7QA4DKx0gJAWTGjBQAAYBGCFgAAgEUIWgAAABYhaAEAAFiEoAUAAGARghYAAIBFCFoAAAAWIWgBAABY5P8DAlKY5Pjs4EkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_acc_values, label='Training accuracy')\n",
    "plt.plot(val_acc_values, label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ1ElEQVR4nO3df0xV9/3H8df1B1fbwnWIcLkVLWorS/2xzCkjtq6tRGSL8VcW7fqHLo1GxGbq2i6YVdttGZtLtqaL0v2xyJpV25r5IzULiULBbEMbrcaYTSKETYyAq4n3IlY08vn+4bd3vRW0F+/lfe/l+Ug+idx7Dvfd01OevT88eJxzTgAADLJh1gMAAIYmAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEyMsB7gy3p7e3Xp0iWlp6fL4/FYjwMAiJJzTl1dXQoEAho2rP/nOQkXoEuXLikvL896DADAA2pra9P48eP7vT/hXoJLT0+3HgEAEAP3+3ketwDt2LFDjz32mEaNGqXCwkJ9/PHHX2k/XnYDgNRwv5/ncQnQ+++/r82bN2vbtm365JNPNHPmTJWUlOjy5cvxeDgAQDJycTBnzhxXXl4e/vr27dsuEAi4ysrK++4bDAadJBaLxWIl+QoGg/f8eR/zZ0A3b97UyZMnVVxcHL5t2LBhKi4uVmNj413b9/T0KBQKRSwAQOqLeYA+/fRT3b59Wzk5ORG35+TkqKOj467tKysr5fP5wotPwAHA0GD+KbiKigoFg8Hwamtrsx4JADAIYv73gLKysjR8+HB1dnZG3N7Z2Sm/33/X9l6vV16vN9ZjAAASXMyfAaWlpWnWrFmqra0N39bb26va2loVFRXF+uEAAEkqLldC2Lx5s1atWqVvfetbmjNnjt588011d3frhz/8YTweDgCQhOISoBUrVui///2vtm7dqo6ODn3jG99QTU3NXR9MAAAMXR7nnLMe4otCoZB8Pp/1GACABxQMBpWRkdHv/eafggMADE0ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiRHWAwCJZNmyZVHv85e//CUOk9ytqqpqUB5nMJWVlVmPkBCWL18e9T779u2LwySDi2dAAAATBAgAYCLmAXr99dfl8XgiVkFBQawfBgCQ5OLyHtCTTz6pI0eO/O9BRvBWEwAgUlzKMGLECPn9/nh8awBAiojLe0Dnz59XIBDQpEmT9MILL+jChQv9btvT06NQKBSxAACpL+YBKiwsVHV1tWpqalRVVaXW1lY9/fTT6urq6nP7yspK+Xy+8MrLy4v1SACABBTzAJWWlur73/++ZsyYoZKSEv31r3/V1atX9cEHH/S5fUVFhYLBYHi1tbXFeiQAQAKK+6cDxowZoyeeeELNzc193u/1euX1euM9BgAgwcT97wFdu3ZNLS0tys3NjfdDAQCSSMwD9PLLL6uhoUH//ve/9Y9//ENLly7V8OHD9fzzz8f6oQAASSzmL8FdvHhRzz//vK5cuaJx48bpqaee0rFjxzRu3LhYPxQAIIl5nHPOeogvCoVC8vl81mNgiEqw/xyAfg3kAqbS4F7ENBgMKiMjo9/7uRYcAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi7r+QDgCGkqampqj3qauri8MkiY9nQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDB1bCBJFFVVWU9QtJav3699QjoA8+AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXIwUKWnnzp3WI8QcF9REquEZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggouRIiU999xz1iPcU1VVlfUIgDmeAQEATBAgAICJqAN09OhRLVq0SIFAQB6PRwcOHIi43zmnrVu3Kjc3V6NHj1ZxcbHOnz8fq3kBACki6gB1d3dr5syZ2rFjR5/3b9++XW+99ZbefvttHT9+XA8//LBKSkp048aNBx4WAJA6ov4QQmlpqUpLS/u8zzmnN998Uz/96U+1ePFiSdI777yjnJwcHThwQCtXrnywaQEAKSOm7wG1traqo6NDxcXF4dt8Pp8KCwvV2NjY5z49PT0KhUIRCwCQ+mIaoI6ODklSTk5OxO05OTnh+76ssrJSPp8vvPLy8mI5EgAgQZl/Cq6iokLBYDC82trarEcCAAyCmAbI7/dLkjo7OyNu7+zsDN/3ZV6vVxkZGRELAJD6Yhqg/Px8+f1+1dbWhm8LhUI6fvy4ioqKYvlQAIAkF/Wn4K5du6bm5ubw162trTp9+rQyMzM1YcIEbdy4Ub/4xS/0+OOPKz8/X6+99poCgYCWLFkSy7kBAEku6gCdOHFCzz77bPjrzZs3S5JWrVql6upqvfrqq+ru7tbatWt19epVPfXUU6qpqdGoUaNiNzUAIOl5nHPOeogvCoVC8vl81mMggezcuTPqfcrKyuIwSd+ampqi3mfLli1R77Nv376o9wEsBYPBe76vb/4pOADA0ESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATUf86BmCwDeaVrQeirq4u6n24sjXAMyAAgBECBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQXI8WgOnfunPUIMXfkyBHrEYCkxDMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMCExznnrIf4olAoJJ/PZz0G4iTBTjczTU1NUe9TV1cX9T7r16+Peh8gVoLBoDIyMvq9n2dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJLkaKQZVgpxv6MZCLpW7ZsiXqffbt2xf1PkgeXIwUAJCQCBAAwETUATp69KgWLVqkQCAgj8ejAwcORNy/evVqeTyeiLVw4cJYzQsASBFRB6i7u1szZ87Ujh07+t1m4cKFam9vD689e/Y80JAAgNQzItodSktLVVpaes9tvF6v/H7/gIcCAKS+uLwHVF9fr+zsbE2dOlVlZWW6cuVKv9v29PQoFApFLABA6ot5gBYuXKh33nlHtbW1+vWvf62GhgaVlpbq9u3bfW5fWVkpn88XXnl5ebEeCQCQgKJ+Ce5+Vq5cGf7z9OnTNWPGDE2ePFn19fWaP3/+XdtXVFRo8+bN4a9DoRARAoAhIO4fw540aZKysrLU3Nzc5/1er1cZGRkRCwCQ+uIeoIsXL+rKlSvKzc2N90MBAJJI1C/BXbt2LeLZTGtrq06fPq3MzExlZmbqjTfe0PLly+X3+9XS0qJXX31VU6ZMUUlJSUwHBwAkt6gDdOLECT377LPhrz9//2bVqlWqqqrSmTNn9Kc//UlXr15VIBDQggUL9POf/1xerzd2UwMAkh4XI0XCW7ZsWdT7FBcXx2GSvpWVlQ3aY6WaqqqqqPdZv359HCZBPHAxUgBAQiJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJroYNGNi5c2fU+3DV7Tu4gnby4GrYAICERIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GKkQAobyEVPpcS+8GlTU1PU+xQUFMRhEtwPFyMFACQkAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDECOsBAHw1A7mwaCJfVFTiwqJDHc+AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXIw0xQzkgpUDtX79+kF7rES2bNmyqPf55S9/GfU+U6dOjXqfRLdlyxbrEWCIZ0AAABMECABgIqoAVVZWavbs2UpPT1d2draWLFly1+/zuHHjhsrLyzV27Fg98sgjWr58uTo7O2M6NAAg+UUVoIaGBpWXl+vYsWM6fPiwbt26pQULFqi7uzu8zaZNm/Thhx9q7969amho0KVLlwb0GjkAILVF9SGEmpqaiK+rq6uVnZ2tkydPat68eQoGg/rjH/+o3bt367nnnpMk7dq1S1//+td17Ngxffvb347d5ACApPZA7wEFg0FJUmZmpiTp5MmTunXrloqLi8PbFBQUaMKECWpsbOzze/T09CgUCkUsAEDqG3CAent7tXHjRs2dO1fTpk2TJHV0dCgtLU1jxoyJ2DYnJ0cdHR19fp/Kykr5fL7wysvLG+hIAIAkMuAAlZeX6+zZs3rvvfceaICKigoFg8Hwamtre6DvBwBIDgP6i6gbNmzQoUOHdPToUY0fPz58u9/v182bN3X16tWIZ0GdnZ3y+/19fi+v1yuv1zuQMQAASSyqZ0DOOW3YsEH79+9XXV2d8vPzI+6fNWuWRo4cqdra2vBtTU1NunDhgoqKimIzMQAgJUT1DKi8vFy7d+/WwYMHlZ6eHn5fx+fzafTo0fL5fHrxxRe1efNmZWZmKiMjQy+99JKKior4BBwAIEJUAaqqqpIkPfPMMxG379q1S6tXr5Yk/e53v9OwYcO0fPly9fT0qKSkZFCvTwYASA4e55yzHuKLQqGQfD6f9RhJazD/dX7+PyTRGMgFTAfrYp9Sal7wc7B4PB7rEZBggsGgMjIy+r2fa8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABFfDTjED+dUXZWVlcZgEiaCpqWlA+23ZsiXqffbt2zegx0Lq4mrYAICERIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGE9AICvpqqqKup91q9fH4dJgNjgGRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYMLjnHPWQ3xRKBSSz+ezHmNIOXfu3ID2mzp1aown6VtTU1PU+9TV1cVhkr5xwU+gb8FgUBkZGf3ezzMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDECOsBYK+goMB6BABDEM+AAAAmCBAAwERUAaqsrNTs2bOVnp6u7OxsLVmy5K7f1fLMM8/I4/FErHXr1sV0aABA8osqQA0NDSovL9exY8d0+PBh3bp1SwsWLFB3d3fEdmvWrFF7e3t4bd++PaZDAwCSX1QfQqipqYn4urq6WtnZ2Tp58qTmzZsXvv2hhx6S3++PzYQAgJT0QO8BBYNBSVJmZmbE7e+++66ysrI0bdo0VVRU6Pr16/1+j56eHoVCoYgFABgC3ADdvn3bfe9733Nz586NuP0Pf/iDq6mpcWfOnHF//vOf3aOPPuqWLl3a7/fZtm2bk8RisVisFFvBYPCeHRlwgNatW+cmTpzo2tra7rldbW2tk+Sam5v7vP/GjRsuGAyGV1tbm/lBY7FYLNaDr/sFaEB/EXXDhg06dOiQjh49qvHjx99z28LCQklSc3OzJk+efNf9Xq9XXq93IGMAAJJYVAFyzumll17S/v37VV9fr/z8/Pvuc/r0aUlSbm7ugAYEAKSmqAJUXl6u3bt36+DBg0pPT1dHR4ckyefzafTo0WppadHu3bv13e9+V2PHjtWZM2e0adMmzZs3TzNmzIjLPwAAIElF876P+nmdb9euXc455y5cuODmzZvnMjMzndfrdVOmTHGvvPLKfV8H/KJgMGj+uiWLxWKxHnzd72e/5//DkjBCoZB8Pp/1GACABxQMBpWRkdHv/VwLDgBgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIuEC5JyzHgEAEAP3+3mecAHq6uqyHgEAEAP3+3nucQn2lKO3t1eXLl1Senq6PB5PxH2hUEh5eXlqa2tTRkaG0YT2OA53cBzu4DjcwXG4IxGOg3NOXV1dCgQCGjas/+c5IwZxpq9k2LBhGj9+/D23ycjIGNIn2Oc4DndwHO7gONzBcbjD+jj4fL77bpNwL8EBAIYGAgQAMJFUAfJ6vdq2bZu8Xq/1KKY4DndwHO7gONzBcbgjmY5Dwn0IAQAwNCTVMyAAQOogQAAAEwQIAGCCAAEATCRNgHbs2KHHHntMo0aNUmFhoT7++GPrkQbd66+/Lo/HE7EKCgqsx4q7o0ePatGiRQoEAvJ4PDpw4EDE/c45bd26Vbm5uRo9erSKi4t1/vx5m2Hj6H7HYfXq1XedHwsXLrQZNk4qKys1e/ZspaenKzs7W0uWLFFTU1PENjdu3FB5ebnGjh2rRx55RMuXL1dnZ6fRxPHxVY7DM888c9f5sG7dOqOJ+5YUAXr//fe1efNmbdu2TZ988olmzpypkpISXb582Xq0Qffkk0+qvb09vP72t79ZjxR33d3dmjlzpnbs2NHn/du3b9dbb72lt99+W8ePH9fDDz+skpIS3bhxY5Anja/7HQdJWrhwYcT5sWfPnkGcMP4aGhpUXl6uY8eO6fDhw7p165YWLFig7u7u8DabNm3Shx9+qL1796qhoUGXLl3SsmXLDKeOva9yHCRpzZo1EefD9u3bjSbuh0sCc+bMceXl5eGvb9++7QKBgKusrDScavBt27bNzZw503oMU5Lc/v37w1/39vY6v9/vfvOb34Rvu3r1qvN6vW7Pnj0GEw6OLx8H55xbtWqVW7x4sck8Vi5fvuwkuYaGBufcnX/3I0eOdHv37g1v869//ctJco2NjVZjxt2Xj4Nzzn3nO99xP/rRj+yG+goS/hnQzZs3dfLkSRUXF4dvGzZsmIqLi9XY2Gg4mY3z588rEAho0qRJeuGFF3ThwgXrkUy1traqo6Mj4vzw+XwqLCwckudHfX29srOzNXXqVJWVlenKlSvWI8VVMBiUJGVmZkqSTp48qVu3bkWcDwUFBZowYUJKnw9fPg6fe/fdd5WVlaVp06apoqJC169ftxivXwl3MdIv+/TTT3X79m3l5ORE3J6Tk6Nz584ZTWWjsLBQ1dXVmjp1qtrb2/XGG2/o6aef1tmzZ5Wenm49nomOjg5J6vP8+Py+oWLhwoVatmyZ8vPz1dLSoi1btqi0tFSNjY0aPny49Xgx19vbq40bN2ru3LmaNm2apDvnQ1pamsaMGROxbSqfD30dB0n6wQ9+oIkTJyoQCOjMmTP6yU9+oqamJu3bt89w2kgJHyD8T2lpafjPM2bMUGFhoSZOnKgPPvhAL774ouFkSAQrV64M/3n69OmaMWOGJk+erPr6es2fP99wsvgoLy/X2bNnh8T7oPfS33FYu3Zt+M/Tp09Xbm6u5s+fr5aWFk2ePHmwx+xTwr8El5WVpeHDh9/1KZbOzk75/X6jqRLDmDFj9MQTT6i5udl6FDOfnwOcH3ebNGmSsrKyUvL82LBhgw4dOqSPPvoo4te3+P1+3bx5U1evXo3YPlXPh/6OQ18KCwslKaHOh4QPUFpammbNmqXa2trwbb29vaqtrVVRUZHhZPauXbumlpYW5ebmWo9iJj8/X36/P+L8CIVCOn78+JA/Py5evKgrV66k1PnhnNOGDRu0f/9+1dXVKT8/P+L+WbNmaeTIkRHnQ1NTky5cuJBS58P9jkNfTp8+LUmJdT5Yfwriq3jvvfec1+t11dXV7p///Kdbu3atGzNmjOvo6LAebVD9+Mc/dvX19a61tdX9/e9/d8XFxS4rK8tdvnzZerS46urqcqdOnXKnTp1yktxvf/tbd+rUKfef//zHOefcr371KzdmzBh38OBBd+bMGbd48WKXn5/vPvvsM+PJY+tex6Grq8u9/PLLrrGx0bW2trojR464b37zm+7xxx93N27csB49ZsrKypzP53P19fWuvb09vK5fvx7eZt26dW7ChAmurq7OnThxwhUVFbmioiLDqWPvfsehubnZ/exnP3MnTpxwra2t7uDBg27SpElu3rx5xpNHSooAOefc73//ezdhwgSXlpbm5syZ444dO2Y90qBbsWKFy83NdWlpae7RRx91K1ascM3NzdZjxd1HH33kJN21Vq1a5Zy781Hs1157zeXk5Div1+vmz5/vmpqabIeOg3sdh+vXr7sFCxa4cePGuZEjR7qJEye6NWvWpNz/pPX1zy/J7dq1K7zNZ5995tavX+++9rWvuYceesgtXbrUtbe32w0dB/c7DhcuXHDz5s1zmZmZzuv1uilTprhXXnnFBYNB28G/hF/HAAAwkfDvAQEAUhMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYOL/ADpEfitNJ2bgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class = 5\n",
      "Actual class = 5\n"
     ]
    }
   ],
   "source": [
    "# visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# pick a random image from the test set\n",
    "idx = np.random.randint(0, test_set[0].shape[0])\n",
    "img = test_set_x[idx:idx+1]\n",
    "# plot the image\n",
    "plt.imshow(img[0][0], cmap=cm.Greys_r)\n",
    "plt.show()\n",
    "\n",
    "# get predictions\n",
    "test_X_val.copyfrom(img)\n",
    "test_y_val.copyfrom(convert_to_one_hot(test_set_y[idx:idx+1]))\n",
    "_, _, _, _, _, _, _, _, _, _, _, _, _, test_y_predicted = executor.run(\n",
    "    feed_dict={\n",
    "        X: test_X_val,\n",
    "        y_: test_y_val,\n",
    "        F1: F1_val,\n",
    "        BN1_gamma: BN1_gamma_val,\n",
    "        BN1_beta: BN1_beta_val,\n",
    "        F2: F2_val,\n",
    "        BN2_gamma: BN2_gamma_val,\n",
    "        BN2_beta: BN2_beta_val,\n",
    "        W1: W1_val,\n",
    "        W2: W2_val,\n",
    "        W3: W3_val,\n",
    "        b1: b1_val,\n",
    "        b2: b2_val,\n",
    "        b3: b3_val},\n",
    "    convert_to_numpy_ret_vals=True);\n",
    "print(\"Predicted class = %d\" % np.argmax(test_y_predicted))\n",
    "print(\"Actual class = %d\" % test_set_y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medoflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
