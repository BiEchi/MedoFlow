{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["train = pd.read_json('train.jsonl', lines=True)\n","valid = pd.read_json('valid.jsonl', lines=True)\n","test = pd.read_json('test.jsonl', lines=True)\n","\n","all_letters = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\"\n","n_letters = len(all_letters)\n","\n","dataset = pd.concat([train, valid, test], ignore_index=True)\n","n_categories = dataset['country'].nunique()\n","all_categories = dataset['country'].unique()\n","categ_to_idx = {categ: idx for idx, categ in enumerate(all_categories)}\n","idx_to_categ = {v: k for k, v in categ_to_idx.items()}\n","longest_name_len = dataset['name'].str.len().max()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'English': 0, 'Russian': 1, 'Italian': 2, 'German': 3, 'Japanese': 4, 'Dutch': 5, 'Arabic': 6, 'Chinese': 7, 'Greek': 8, 'Czech': 9, 'Irish': 10, 'Spanish': 11, 'French': 12, 'Polish': 13, 'Vietnamese': 14, 'Korean': 15, 'Portuguese': 16, 'Scottish': 17}\n"]}],"source":["print(categ_to_idx)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import torch\n","\n","# Find letter index from all_letters, e.g. \"a\" = 0\n","def letterToIndex(letter):\n","    return all_letters.find(letter)\n","\n","# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n","def letterToTensor(letter):\n","    tensor = torch.zeros(1, n_letters)\n","    tensor[0][letterToIndex(letter)] = 1\n","    return tensor\n","\n","# Turn a line into a (longest_name_len, 1, n_letters) tensor\n","def lineToTensor(line):\n","    tensor = torch.zeros(len(line), 1, n_letters)\n","    for li, letter in enumerate(line):\n","        tensor[li][0][letterToIndex(letter)] = 1\n","    return tensor"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Creating the Network\n","\n","Before autograd, creating a recurrent neural network in Torch involved\n","cloning the parameters of a layer over several timesteps. The layers\n","held hidden state and gradients which are now entirely handled by the\n","graph itself. This means you can implement a RNN in a very \"pure\" way,\n","as regular feed-forward layers.\n","\n","This RNN module (mostly copied from [the PyTorch for Torch users\n","tutorial](https://pytorch.org/tutorials/beginner/former_torchies/nn_tutorial.html#example-2-recurrent-net))\n","is just 2 linear layers which operate on an input and hidden state, with\n","a LogSoftmax layer after the output.\n","\n","<img src=\"../images/rnn.png\" width=\"80%\">\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RNN(\n","  (relu): ReLU()\n",")\n"]}],"source":["import torch.nn as nn\n","\n","class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, sigma=0.01):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.U = nn.Parameter(\n","            torch.randn(input_size, hidden_size) * sigma)\n","        self.W = nn.Parameter(\n","            torch.randn(hidden_size, hidden_size) * sigma)\n","        self.b1 = nn.Parameter(torch.zeros(hidden_size))\n","        self.relu = nn.ReLU()\n","        self.V = nn.Parameter(\n","            torch.randn(hidden_size, output_size) * sigma)\n","        self.b2 = nn.Parameter(torch.zeros(output_size))\n","        \n","    def forward(self, inputs, hidden):\n","        z1 = torch.mm(inputs, self.U)\n","        z2 = torch.mm(hidden, self.W)\n","        hidden = self.relu(z1 + z2 + self.b1)\n","        z3 = torch.mm(hidden, self.V)\n","        output = z3 + self.b2\n","        return output, hidden\n","    \n","    def initHidden(self):\n","        return torch.zeros(1, self.hidden_size)\n","\n","n_hidden = 128\n","rnn = RNN(n_letters, n_hidden, n_categories)\n","print(rnn)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["To run a step of this network we need to pass an input (in our case, the\n","Tensor for the current letter) and a previous hidden state (which we\n","initialize as zeros at first). We'll get back the output (probability of\n","each language) and a next hidden state (which we keep for the next\n","step)."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 18])\n"]}],"source":["input = lineToTensor('Albert')\n","hidden = torch.zeros(1, n_hidden)\n","output, next_hidden = rnn(input[0], hidden)\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{},"source":["As you can see the output is a ``<1 x n_categories>`` Tensor, where\n","every item is the likelihood of that category (higher is more likely).\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n","optimizer = optim.SGD(rnn.parameters(), lr=learning_rate)\n","model = RNN(n_letters, n_hidden, n_categories)\n","n_epochs = 20\n","\n","def train_tensor(category_tensor, line_tensor):\n","    hidden = rnn.initHidden()\n","\n","    for i in range(line_tensor.size()[0]):\n","        output, hidden = rnn(line_tensor[i], hidden)\n","\n","    optimizer.zero_grad()\n","    loss = criterion(output, category_tensor)\n","    loss.backward()\n","    optimizer.step()\n","\n","    return output, loss.item()\n","\n","def evaluate_tensor(line_tensor):\n","    hidden = rnn.initHidden()\n","\n","    for i in range(line_tensor.size()[0]):\n","        output, hidden = rnn(line_tensor[i], hidden)\n","\n","    return output"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1 / 20\n","train_acc: 0.012819286329283459\n","valid_acc: 0.011194029850746268\n"]}],"source":["valid_acc_list = []\n","train_acc_list = []\n","loss_list = []\n","for epoch in range(n_epochs):\n","    print(f'Epoch: {epoch+1} / {n_epochs}')\n","    \n","    # calculate the accuracy on valid set\n","    correct_train = 0\n","    total_train = 0\n","    for _, row in train.iterrows():\n","        category = row['country']\n","        line = row['name']\n","        category_tensor = torch.tensor([categ_to_idx[category]], dtype=torch.long)\n","        line_tensor = lineToTensor(line)\n","        \n","        output = evaluate_tensor(line_tensor)\n","            \n","        # calculate the accuracy on train set\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        if pred.item() == category_tensor.item():\n","            correct_train += 1\n","            \n","    # calculate the accuracy on train set\n","    train_acc = correct_train / len(train)\n","    print(f'train_acc: {train_acc}')\n","    train_acc_list.append(train_acc)\n","    \n","    # calculate the accuracy on valid set\n","    correct_val = 0\n","    total_val = 0\n","    for _, row in valid.iterrows():\n","        category = row['country']\n","        line = row['name']\n","        category_tensor = torch.tensor([categ_to_idx[category]], dtype=torch.long)\n","        line_tensor = lineToTensor(line)\n","        \n","        output = evaluate_tensor(line_tensor)\n","            \n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        if pred.item() == category_tensor.item():\n","            correct_val += 1\n","            \n","    # calculate the accuracy on valid set\n","    valid_acc = correct_val / len(valid)\n","    print(f'valid_acc: {valid_acc}')\n","    valid_acc_list.append(valid_acc)\n","    \n","    # do training on the train set\n","    for _, row in train.iterrows():\n","        category = row['country']\n","        line = row['name']\n","        category_tensor = torch.tensor([categ_to_idx[category]], dtype=torch.long)\n","        line_tensor = lineToTensor(line)\n","        \n","        # forward pass\n","        output, loss = train_tensor(category_tensor, line_tensor)\n","    \n","    loss_list.append(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save train, acc, loss lists to file\n","import json\n","with open(\"pytorch_results.json\" , \"w\") as f:\n","    json.dump({\"train_acc\": train_acc_list, \"val_acc\": valid_acc_list, \"loss\": loss_list}, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test_acc: 0.5423242467718795\n"]}],"source":["# infer in the test set\n","test_acc_list = []\n","correct_test = 0\n","total_test = 0\n","for i, row in test.iterrows():\n","    category = row['country']\n","    line = row['name']\n","    category_tensor = torch.tensor([categ_to_idx[category]], dtype=torch.long)\n","    line_tensor = lineToTensor(line)\n","    \n","    output = evaluate_tensor(line_tensor)\n","        \n","    pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","    if pred.item() == category_tensor.item():\n","        correct_test += 1\n","\n","# calculate the accuracy on test set\n","test_acc = correct_test / len(test)\n","print(f'test_acc: {test_acc}')\n","test_acc_list.append(test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted countries: ['Russian', 'English', 'Japanese']\n"]}],"source":["# give a real name and predict its country\n","line = 'Junyan Li'\n","line_tensor = lineToTensor(line)\n","output = evaluate_tensor(line_tensor)\n","# get the top-3 predictions\n","_, pred = output.topk(3, dim=1)\n","print(f'Predicted countries: {[idx_to_categ[p.item()] for p in pred[0]]}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"medoflow","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
