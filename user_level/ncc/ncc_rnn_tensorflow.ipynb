{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 13:18:04.991581: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.jsonl', lines=True)\n",
    "valid = pd.read_json('valid.jsonl', lines=True)\n",
    "test = pd.read_json('test.jsonl', lines=True)\n",
    "\n",
    "all_letters = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "dataset = pd.concat([train, valid, test], ignore_index=True)\n",
    "n_categories = dataset['country'].nunique()\n",
    "all_categories = dataset['country'].unique()\n",
    "categ_to_idx = {categ: idx for idx, categ in enumerate(all_categories)}\n",
    "idx_to_categ = {v: k for k, v in categ_to_idx.items()}\n",
    "longest_name_len = dataset['name'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = np.zeros((1, n_letters), dtype=np.float32)\n",
    "    tensor[0][letterToIndex(letter)] = 1.0\n",
    "    return tf.convert_to_tensor(tensor)\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = np.zeros((len(line), 1, n_letters), dtype=np.float32)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1.0\n",
    "    return tf.convert_to_tensor(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size, sigma=0.01):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.U = tf.Variable(\n",
    "            tf.random.normal((input_size, hidden_size)) * sigma)\n",
    "        self.W = tf.Variable(\n",
    "            tf.random.normal((hidden_size, hidden_size)) * sigma)\n",
    "        self.b1 = tf.Variable(tf.zeros((hidden_size,)))\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.V = tf.Variable(\n",
    "            tf.random.normal((hidden_size, output_size)) * sigma)\n",
    "        self.b2 = tf.Variable(tf.zeros((output_size,)))\n",
    "        self.softmax = tf.keras.layers.Softmax(axis=1)\n",
    "        \n",
    "    def call(self, inputs, hidden):\n",
    "        z1 = tf.matmul(inputs, self.U)\n",
    "        z2 = tf.matmul(hidden, self.W)\n",
    "        hidden = self.relu(z1 + z2 + self.b1)\n",
    "        z3 = tf.matmul(hidden, self.V)\n",
    "        output = self.softmax(z3 + self.b2)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.hidden_size))\n",
    "    \n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "learning_rate = 0.005\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "n_epochs = 20\n",
    "\n",
    "\n",
    "def train_tensor(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden(batch_size=1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        for i in range(line_tensor.shape[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "        loss = criterion(category_tensor, output)\n",
    "        gradients = tape.gradient(loss, rnn.trainable_variables)\n",
    "        \n",
    "    optimizer.apply_gradients(zip(gradients, rnn.trainable_variables))\n",
    "\n",
    "    return output, loss.numpy()\n",
    "\n",
    "def evaluate_tensor(line_tensor):\n",
    "    hidden = rnn.initHidden(batch_size=1)\n",
    "\n",
    "    for i in range(line_tensor.shape[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1], shape=(1,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.05551922 0.05559709 0.0555092  0.05557127 0.05554948 0.05553937\n",
      "  0.05551817 0.05559023 0.0555577  0.05545083 0.05555725 0.05555254\n",
      "  0.05563111 0.05554031 0.05555001 0.05561183 0.05555777 0.05559664]], shape=(1, 18), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(category_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m category_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant([categ_to_idx[category]], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint64)\n\u001b[1;32m     15\u001b[0m line_tensor \u001b[39m=\u001b[39m lineToTensor(line)\n\u001b[0;32m---> 17\u001b[0m output \u001b[39m=\u001b[39m evaluate_tensor(line_tensor)\n\u001b[1;32m     18\u001b[0m pred \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39margmax(output, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m pred\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m category_tensor\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mevaluate_tensor\u001b[0;34m(line_tensor)\u001b[0m\n\u001b[1;32m     21\u001b[0m hidden \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39minitHidden(batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(line_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m---> 24\u001b[0m     output, hidden \u001b[39m=\u001b[39m rnn(line_tensor[i], hidden)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/site-packages/keras/engine/training.py:558\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    556\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 558\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/site-packages/keras/engine/base_layer.py:1123\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     name_scope \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_unnested_name_scope()\n\u001b[1;32m   1121\u001b[0m     call_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autographed_call()\n\u001b[0;32m-> 1123\u001b[0m call_fn \u001b[39m=\u001b[39m traceback_utils\u001b[39m.\u001b[39;49minject_argument_info_in_traceback(\n\u001b[1;32m   1124\u001b[0m     call_fn,\n\u001b[1;32m   1125\u001b[0m     object_name\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   1126\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlayer \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m (type \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m   1127\u001b[0m     ),\n\u001b[1;32m   1128\u001b[0m )\n\u001b[1;32m   1129\u001b[0m \u001b[39mwith\u001b[39;00m contextlib\u001b[39m.\u001b[39mExitStack() \u001b[39mas\u001b[39;00m namescope_stack:\n\u001b[1;32m   1130\u001b[0m     \u001b[39mif\u001b[39;00m _is_name_scope_on_model_declaration_enabled:\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:160\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback\u001b[0;34m(fn, object_name)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mdel\u001b[39;00m signature\n\u001b[1;32m    158\u001b[0m         \u001b[39mdel\u001b[39;00m bound_signature\n\u001b[0;32m--> 160\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mdecorator\u001b[39m.\u001b[39;49mmake_decorator(fn, error_handler)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/site-packages/tensorflow/python/util/tf_decorator.py:136\u001b[0m, in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m decorator_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m   decorator_name \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mcurrentframe()\u001b[39m.\u001b[39mf_back\u001b[39m.\u001b[39mf_code\u001b[39m.\u001b[39mco_name\n\u001b[0;32m--> 136\u001b[0m decorator \u001b[39m=\u001b[39m TFDecorator(decorator_name, target, decorator_doc,\n\u001b[1;32m    137\u001b[0m                         decorator_argspec)\n\u001b[1;32m    138\u001b[0m \u001b[39msetattr\u001b[39m(decorator_func, \u001b[39m'\u001b[39m\u001b[39m_tf_decorator\u001b[39m\u001b[39m'\u001b[39m, decorator)\n\u001b[1;32m    139\u001b[0m \u001b[39m# Objects that are callables (e.g., a functools.partial object) may not have\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m# the following attributes.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/site-packages/tensorflow/python/util/tf_decorator.py:332\u001b[0m, in \u001b[0;36mTFDecorator.__init__\u001b[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39melif\u001b[39;00m callable(target):\n\u001b[1;32m    331\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__signature__ \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49msignature(target)\n\u001b[1;32m    333\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m     \u001b[39m# Certain callables such as builtins can not be inspected for signature.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/inspect.py:3113\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msignature\u001b[39m(obj, \u001b[39m*\u001b[39m, follow_wrapped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   3112\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3113\u001b[0m     \u001b[39mreturn\u001b[39;00m Signature\u001b[39m.\u001b[39;49mfrom_callable(obj, follow_wrapped\u001b[39m=\u001b[39;49mfollow_wrapped)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/inspect.py:2862\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   2860\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_callable\u001b[39m(\u001b[39mcls\u001b[39m, obj, \u001b[39m*\u001b[39m, follow_wrapped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   2861\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2862\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_callable(obj, sigcls\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m,\n\u001b[1;32m   2863\u001b[0m                                     follow_wrapper_chains\u001b[39m=\u001b[39;49mfollow_wrapped)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/inspect.py:2266\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m is not a callable object\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(obj))\n\u001b[1;32m   2263\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, types\u001b[39m.\u001b[39mMethodType):\n\u001b[1;32m   2264\u001b[0m     \u001b[39m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[39m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[0;32m-> 2266\u001b[0m     sig \u001b[39m=\u001b[39m _get_signature_of(obj\u001b[39m.\u001b[39;49m\u001b[39m__func__\u001b[39;49m)\n\u001b[1;32m   2268\u001b[0m     \u001b[39mif\u001b[39;00m skip_bound_arg:\n\u001b[1;32m   2269\u001b[0m         \u001b[39mreturn\u001b[39;00m _signature_bound_method(sig)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/inspect.py:2325\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[39mreturn\u001b[39;00m sig\u001b[39m.\u001b[39mreplace(parameters\u001b[39m=\u001b[39mnew_params)\n\u001b[1;32m   2322\u001b[0m \u001b[39mif\u001b[39;00m isfunction(obj) \u001b[39mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2323\u001b[0m     \u001b[39m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2324\u001b[0m     \u001b[39m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2325\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[1;32m   2326\u001b[0m                                     skip_bound_arg\u001b[39m=\u001b[39;49mskip_bound_arg)\n\u001b[1;32m   2328\u001b[0m \u001b[39mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2329\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2330\u001b[0m                                    skip_bound_arg\u001b[39m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/inspect.py:2241\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2236\u001b[0m     parameters\u001b[39m.\u001b[39mappend(Parameter(name, annotation\u001b[39m=\u001b[39mannotation,\n\u001b[1;32m   2237\u001b[0m                                 kind\u001b[39m=\u001b[39m_VAR_KEYWORD))\n\u001b[1;32m   2239\u001b[0m \u001b[39m# Is 'func' is a pure Python function - don't validate the\u001b[39;00m\n\u001b[1;32m   2240\u001b[0m \u001b[39m# parameters list (for correct order and defaults), it should be OK.\u001b[39;00m\n\u001b[0;32m-> 2241\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(parameters,\n\u001b[1;32m   2242\u001b[0m            return_annotation\u001b[39m=\u001b[39;49mannotations\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mreturn\u001b[39;49m\u001b[39m'\u001b[39;49m, _empty),\n\u001b[1;32m   2243\u001b[0m            __validate_parameters__\u001b[39m=\u001b[39;49mis_duck_function)\n",
      "File \u001b[0;32m~/miniconda3/envs/medoflow/lib/python3.9/inspect.py:2832\u001b[0m, in \u001b[0;36mSignature.__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m   2829\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2830\u001b[0m         params \u001b[39m=\u001b[39m OrderedDict((param\u001b[39m.\u001b[39mname, param) \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m parameters)\n\u001b[0;32m-> 2832\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameters \u001b[39m=\u001b[39m types\u001b[39m.\u001b[39;49mMappingProxyType(params)\n\u001b[1;32m   2833\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_annotation \u001b[39m=\u001b[39m return_annotation\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc_list = []\n",
    "valid_acc_list = []\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch+1} / {n_epochs}')\n",
    "    \n",
    "    # calculate the accuracy on train set\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for _, row in train.iterrows():\n",
    "        category = row['country']\n",
    "        line = row['name']\n",
    "        category_tensor = tf.constant([categ_to_idx[category]], dtype=tf.int64)\n",
    "        line_tensor = lineToTensor(line)\n",
    "        \n",
    "        output = evaluate_tensor(line_tensor)\n",
    "        pred = tf.argmax(output, axis=1)\n",
    "        if pred.numpy()[0] == category_tensor.numpy()[0]:\n",
    "            correct_train += 1\n",
    "            \n",
    "    # calculate the accuracy on train set\n",
    "    train_acc = correct_train / len(train)\n",
    "    print(f'train_acc: {train_acc}')\n",
    "    train_acc_list.append(train_acc)\n",
    "    \n",
    "    # calculate the accuracy on valid set\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    for _, row in valid.iterrows():\n",
    "        category = row['country']\n",
    "        line = row['name']\n",
    "        category_tensor = tf.constant([categ_to_idx[category]], dtype=tf.int64)\n",
    "        line_tensor = lineToTensor(line)\n",
    "        \n",
    "        output = evaluate_tensor(line_tensor)\n",
    "        pred = tf.argmax(output, axis=1)\n",
    "        if pred.numpy()[0] == category_tensor.numpy()[0]:\n",
    "            correct_val += 1\n",
    "            \n",
    "    # calculate the accuracy on valid set\n",
    "    valid_acc = correct_val / len(valid)\n",
    "    print(f'valid_acc: {valid_acc}')\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    \n",
    "    # do training on the train set\n",
    "    for _, row in train.iterrows():\n",
    "        category = row['country']\n",
    "        line = row['name']\n",
    "        category_tensor = tf.constant([categ_to_idx[category]], dtype=tf.int64)\n",
    "        line_tensor = lineToTensor(line)\n",
    "        \n",
    "        # forward pass\n",
    "        output, loss = train_tensor(category_tensor, line_tensor)\n",
    "    \n",
    "    loss_list.append(float(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_acc_values = [] val_acc_values = [] loss_values = [] to a json file\n",
    "import json\n",
    "with open(\"tensorflow_results.json\" , \"w\") as f:\n",
    "    json.dump({\"train_acc\": train_acc_list, \"valid_acc\": valid_acc_list, \"loss\": loss_list}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medoflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
